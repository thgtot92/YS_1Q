#!/usr/bin/env python3
"""
ê°•í™”ëœ CRAG ì‹œìŠ¤í…œ ì •ëŸ‰ì  í‰ê°€ í”„ë ˆì„ì›Œí¬ (LLaMA ëª¨ë¸ ë¹„êµ ì¶”ê°€)
- Gemini vs LLaMA ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
- CRAG vs Standard RAG ë¹„êµ
- 4ê°€ì§€ ì¡°í•© í‰ê°€ (2x2 ë§¤íŠ¸ë¦­ìŠ¤)
"""

import pandas as pd
import json
from datetime import datetime, timedelta
import os
import time
from typing import List, Dict, Tuple
import random
import numpy as np

# ê¸°ì¡´ ëª¨ë“ˆë“¤ import
from llm_reporter import get_llm_report, compare_llm_models
from news_api_caller import NaverNewsSearcher, search_news_advanced, format_news_data, match_news_before_events
from seibro_disclosure_scraper import fetch_disclosures_with_fallback, match_disclosures_before_events
from slack_sender import send_to_slack

class ModelComparisonCRAGEvaluator:
    """Geminiì™€ LLaMA ëª¨ë¸ì„ ë¹„êµí•˜ëŠ” CRAG í‰ê°€ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.evaluation_results = []
        self.test_cases = []
        
        # API ì„¤ì •
        self.client_id = os.getenv("NAVER_CLIENT_ID") or "JEuS9xkuWGpP40lsI9Kz"
        self.client_secret = os.getenv("NAVER_CLIENT_SECRET") or "I6nujCm0xF"

        # Groq API í‚¤ í™•ì¸
        self.groq_api_key = "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"
                
        # í™˜ê²½ë³€ìˆ˜ì— ì„¤ì • (llm_reporter.pyê°€ ì½ì„ ìˆ˜ ìˆë„ë¡)
        os.environ["GROQ_API_KEY"] = self.groq_api_key

        # Groq API ì—°ê²° í…ŒìŠ¤íŠ¸
        try:
            from llm_reporter import test_groq_connection, reinitialize_groq_client
            print("\nğŸ” Groq API ì—°ê²° í™•ì¸ ì¤‘...")
            
            # Groq í´ë¼ì´ì–¸íŠ¸ ì¬ì´ˆê¸°í™”
            reinitialize_groq_client(self.groq_api_key)
            
            if test_groq_connection():
                print("âœ… Groq API ì—°ê²° ì„±ê³µ! LLaMA ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                print("âš ï¸ Groq API ì—°ê²° ì‹¤íŒ¨. ìƒˆ API í‚¤ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                print("1. https://console.groq.com ì—ì„œ ë¬´ë£Œ API í‚¤ ë°œê¸‰")
                print("2. ì½”ë“œì—ì„œ self.groq_api_key ê°’ì„ ìƒˆ í‚¤ë¡œ ë³€ê²½")
        except Exception as e:
            print(f"âš ï¸ Groq API í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def create_test_cases(self) -> List[Dict]:
        """í‰ê°€ìš© í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„± (ê°„ì†Œí™”)"""
        
        test_cases = [
            {
                "type": "model_comparison",
                "stock_code": "005930",
                "stock_name": "ì‚¼ì„±ì „ì", 
                "date": "2025-06-09",
                "description": "ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸",
                "expected_events": ["ìƒìŠ¹", "í•˜ë½"],
                "difficulty": "medium"
            },
            {
                "type": "model_comparison",
                "stock_code": "000660", 
                "stock_name": "SKí•˜ì´ë‹‰ìŠ¤",
                "date": "2025-06-04", 
                "description": "ë°˜ë„ì²´ ì—…ì¢… ëª¨ë¸ ë¹„êµ",
                "expected_events": ["ìƒìŠ¹", "í•˜ë½"],
                "difficulty": "medium"
            }
        ]
        
        self.test_cases = test_cases
        return test_cases
    
    def run_model_comparison_evaluation(self, test_case_index: int = None) -> Dict:
        """
        4ê°€ì§€ ì¡°í•©ìœ¼ë¡œ ëª¨ë¸ ë¹„êµ í‰ê°€ ì‹¤í–‰
        1. Gemini + Standard RAG
        2. Gemini + Enhanced CRAG
        3. LLaMA + Standard RAG
        4. LLaMA + Enhanced CRAG
        """
        
        print("ğŸš€ CRAG vs RAG + Gemini vs LLaMA ë¹„êµ í‰ê°€ ì‹œì‘")
        print("="*70)
        
        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì„ íƒ
        if test_case_index is not None:
            test_cases = [self.test_cases[test_case_index]]
        else:
            test_cases = self.create_test_cases()
        
        all_evaluation_results = []
        
        for i, test_case in enumerate(test_cases):
            print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i+1}/{len(test_cases)}")
            print(f"ì¢…ëª©: {test_case['stock_name']} ({test_case['stock_code']})")
            print(f"ë‚ ì§œ: {test_case['date']}")
            print("-"*50)
            
            # ë°ì´í„° ìˆ˜ì§‘ (ê³µí†µ)
            print("\nğŸ“ˆ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            data_collection = self.collect_common_data(
                test_case['stock_code'], 
                test_case['stock_name'], 
                test_case['date']
            )
            
            case_results = {
                "test_case": test_case,
                "models": {},
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            
            # 4ê°€ì§€ ì¡°í•© ì‹¤í–‰
            combinations = [
                ("gemini", "standard_rag", "Gemini + Standard RAG"),
                ("gemini", "enhanced_crag", "Gemini + Enhanced CRAG"),
                ("llama", "standard_rag", "LLaMA + Standard RAG"),
                ("llama", "enhanced_crag", "LLaMA + Enhanced CRAG")
            ]
            
            for model_type, approach, label in combinations:
                print(f"\nğŸ” {label} ì‹¤í–‰ ì¤‘...")
                
                # API ì œí•œ ë°©ì§€ ëŒ€ê¸°
                if model_type == "llama":
                    time.sleep(3)
                
                try:
                    if approach == "standard_rag":
                        result = self.run_standard_rag_with_model(
                            data_collection, 
                            test_case['stock_name'],
                            test_case['date'],
                            model_type
                        )
                    else:  # enhanced_crag
                        result = self.run_enhanced_crag_with_model(
                            data_collection,
                            test_case['stock_name'],
                            test_case['date'],
                            model_type
                        )
                    
                    case_results["models"][f"{model_type}_{approach}"] = {
                        "analysis": result["analysis"],
                        "metadata": result["metadata"],
                        "model": model_type,
                        "approach": approach
                    }
                    print(f"âœ… {label} ì™„ë£Œ")
                    
                except Exception as e:
                    print(f"âŒ {label} ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                    case_results["models"][f"{model_type}_{approach}"] = {
                        "analysis": f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                        "metadata": {},
                        "model": model_type,
                        "approach": approach
                    }
                
                # API í˜¸ì¶œ ê°„ê²©
                time.sleep(5)
            
            # ëª¨ë¸ ê°„ ë¹„êµ í‰ê°€
            print("\nâš–ï¸ ëª¨ë¸ ë¹„êµ í‰ê°€ ì¤‘...")
            comparison_result = self.evaluate_model_combinations(case_results)
            case_results["comparison"] = comparison_result
            
            all_evaluation_results.append(case_results)
            
            # ê²°ê³¼ ì¶œë ¥
            self.print_case_comparison(case_results)
            
            # ë‹¤ìŒ ì¼€ì´ìŠ¤ ëŒ€ê¸°
            if i < len(test_cases) - 1:
                print("\nâ³ ë‹¤ìŒ í…ŒìŠ¤íŠ¸ê¹Œì§€ 20ì´ˆ ëŒ€ê¸°...")
                time.sleep(20)
        
        # ì¢…í•© í‰ê°€
        self.print_overall_comparison(all_evaluation_results)
        self.evaluation_results = all_evaluation_results
        
        return {
            "evaluation_results": all_evaluation_results,
            "summary": self.calculate_comparison_statistics(all_evaluation_results)
        }
    
    def collect_common_data(self, stock_code: str, stock_name: str, date: str) -> Dict:
        """ê³µí†µ ë°ì´í„° ìˆ˜ì§‘ (ì¤‘ë³µ ë°©ì§€)"""
        
        # ì£¼ê°€ ë°ì´í„°
        df = self.robust_fetch_intraday_price(stock_code, date)
        events = self.enhanced_detect_price_events(df)
        
        # ë‰´ìŠ¤ ë°ì´í„°
        searcher = NaverNewsSearcher(self.client_id, self.client_secret)
        raw_news = search_news_advanced(searcher, stock_name, date)
        formatted_news = format_news_data(raw_news)
        analyzed_news = self.intelligent_news_analysis(formatted_news, stock_name)
        
        # ê³µì‹œ ë°ì´í„°
        start_date = (datetime.strptime(date, "%Y-%m-%d") - timedelta(days=3)).strftime("%Y-%m-%d")
        disclosures = fetch_disclosures_with_fallback(stock_name, start_date, date)
        
        # ë§¤ì¹­
        matched_news_dict = match_news_before_events(analyzed_news, events)
        matched_disclosures_dict = match_disclosures_before_events(disclosures, events, hours_before=72)
        
        return {
            "df": df,
            "events": events,
            "formatted_news": formatted_news,
            "analyzed_news": analyzed_news,
            "disclosures": disclosures,
            "matched_news_dict": matched_news_dict,
            "matched_disclosures_dict": matched_disclosures_dict
        }
    
    def run_standard_rag_with_model(self, data: Dict, stock_name: str, date: str, model_type: str) -> Dict:
        """íŠ¹ì • ëª¨ë¸ë¡œ Standard RAG ì‹¤í–‰"""
        
        df = data["df"]
        formatted_news = data["formatted_news"]
        disclosures = data["disclosures"]
        
        # ë°ì´í„° ì¤€ë¹„
        news_text = "\n".join([f"- {news['title']}" for news in formatted_news[:10]])
        disclosure_text = "\n".join([f"- {d['title']}" for d in disclosures[:5]])
        
        first_price = df.iloc[0]['price'] if len(df) > 0 else 0
        last_price = df.iloc[-1]['price'] if len(df) > 0 else 0
        price_change = ((last_price - first_price) / first_price * 100) if first_price > 0 else 0
        
        # í‘œì¤€ RAG í”„ë¡¬í”„íŠ¸
        standard_prompt = f"""
        {date}ì¼ {stock_name} ì£¼ì‹ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”.
        
        ì£¼ê°€ ì •ë³´:
        - ì‹œì‘ê°€: {first_price:,}ì›
        - ì¢…ë£Œê°€: {last_price:,}ì›  
        - ë³€ë™ë¥ : {price_change:.2f}%
        
        ê´€ë ¨ ë‰´ìŠ¤:
        {news_text if news_text.strip() else "- ê´€ë ¨ ë‰´ìŠ¤ ì—†ìŒ"}
        
        ê´€ë ¨ ê³µì‹œ:
        {disclosure_text if disclosure_text.strip() else "- ê´€ë ¨ ê³µì‹œ ì—†ìŒ"}
        
        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¢…í•©ì ì¸ ì£¼ì‹ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.
        """
        
        # ëª¨ë¸ë³„ ë¶„ì„
        analysis = get_llm_report(standard_prompt, model_type=model_type)
        
        metadata = {
            "data_points": len(df),
            "news_count": len(formatted_news),
            "disclosure_count": len(disclosures),
            "price_change": price_change,
            "model_used": model_type
        }
        
        return {"analysis": analysis, "metadata": metadata}
    
    def run_enhanced_crag_with_model(self, data: Dict, stock_name: str, date: str, model_type: str) -> Dict:
        """íŠ¹ì • ëª¨ë¸ë¡œ Enhanced CRAG ì‹¤í–‰"""
        
        events = data["events"]
        matched_news_dict = data["matched_news_dict"]
        matched_disclosures_dict = data["matched_disclosures_dict"]
        
        # CRAG íŠ¹í™” í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.create_enhanced_comprehensive_analysis(
            events, matched_news_dict, matched_disclosures_dict, stock_name, date
        )
        
        # ëª¨ë¸ë³„ ë¶„ì„
        analysis = get_llm_report(prompt, model_type=model_type)
        
        total_matched_news = sum(len(news_list) for news_list in matched_news_dict.values())
        total_matched_disclosures = sum(len(disc_list) for disc_list in matched_disclosures_dict.values())
        
        metadata = {
            "data_points": len(data["df"]),
            "events_detected": len(events),
            "news_relevant": len(data["analyzed_news"]),
            "matched_news": total_matched_news,
            "matched_disclosures": total_matched_disclosures,
            "model_used": model_type
        }
        
        return {"analysis": analysis, "metadata": metadata}
    
    def evaluate_model_combinations(self, case_results: Dict) -> Dict:
        """4ê°€ì§€ ì¡°í•© ê°„ ë¹„êµ í‰ê°€"""
        
        # ê°„ë‹¨í•œ í‰ê°€ ë©”íŠ¸ë¦­
        evaluation = {
            "best_combination": "",
            "scores": {},
            "rankings": []
        }
        
        # ê° ì¡°í•©ë³„ ì ìˆ˜ ê³„ì‚° (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
        for key, result in case_results["models"].items():
            if "analysis" in result and result["analysis"]:
                # ê¸¸ì´, êµ¬ì¡°í™”, í‚¤ì›Œë“œ ë“±ì„ ê¸°ë°˜ìœ¼ë¡œ ì ìˆ˜ ê³„ì‚°
                analysis = result["analysis"]
                score = 0
                
                # ë¶„ì„ ê¸¸ì´ (ì ì ˆí•œ ê¸¸ì´ ì„ í˜¸)
                length = len(analysis)
                if 500 < length < 2000:
                    score += 20
                elif 2000 <= length < 3000:
                    score += 15
                else:
                    score += 10
                
                # êµ¬ì¡°í™” ì •ë„ (ì„¹ì…˜, ë¶ˆë¦¿í¬ì¸íŠ¸ ë“±)
                if "**" in analysis:  # ë³¼ë“œ í…ìŠ¤íŠ¸
                    score += 10
                if "â€¢" in analysis or "-" in analysis:  # ë¶ˆë¦¿í¬ì¸íŠ¸
                    score += 10
                if "1." in analysis or "2." in analysis:  # ë²ˆí˜¸ ë§¤ê¸°ê¸°
                    score += 10
                
                # CRAG íŠ¹í™” í‚¤ì›Œë“œ
                crag_keywords = ["ì¸ê³¼ê´€ê³„", "ì‹œê°„ì ", "ì´ì „", "ì´í›„", "ì›ì¸", "ê²°ê³¼"]
                for keyword in crag_keywords:
                    if keyword in analysis:
                        score += 5
                
                # ë©”íƒ€ë°ì´í„° ì™„ì„±ë„
                metadata = result.get("metadata", {})
                if metadata.get("events_detected", 0) > 0:
                    score += 15
                if metadata.get("matched_news", 0) > 0:
                    score += 10
                
                evaluation["scores"][key] = score
        
        # ìˆœìœ„ ë§¤ê¸°ê¸°
        sorted_combinations = sorted(
            evaluation["scores"].items(), 
            key=lambda x: x[1], 
            reverse=True
        )
        
        evaluation["rankings"] = sorted_combinations
        evaluation["best_combination"] = sorted_combinations[0][0] if sorted_combinations else ""
        
        return evaluation
    
    def print_case_comparison(self, case_results: Dict):
        """ì¼€ì´ìŠ¤ë³„ ë¹„êµ ê²°ê³¼ ì¶œë ¥"""
        
        print("\n" + "="*70)
        print(f"ğŸ“Š {case_results['test_case']['stock_name']} ëª¨ë¸ ë¹„êµ ê²°ê³¼")
        print("="*70)
        
        comparison = case_results.get("comparison", {})
        
        if comparison.get("rankings"):
            print("\nğŸ† ì„±ëŠ¥ ìˆœìœ„:")
            for i, (combo, score) in enumerate(comparison["rankings"], 1):
                model, approach = combo.split("_", 1)
                label = f"{model.upper()} + {approach.replace('_', ' ').title()}"
                print(f"{i}. {label}: {score}ì ")
        
        print("\nğŸ“ˆ ë©”íƒ€ë°ì´í„° ë¹„êµ:")
        print("ì¡°í•©                    | ì´ë²¤íŠ¸ | ë§¤ì¹­ë‰´ìŠ¤ | ë¶„ì„ê¸¸ì´")
        print("-"*60)
        
        for key, result in case_results["models"].items():
            model, approach = key.split("_", 1)
            label = f"{model.upper()} + {approach.replace('_', ' ')}"
            metadata = result.get("metadata", {})
            analysis_length = len(result.get("analysis", ""))
            
            events = metadata.get("events_detected", 0)
            matched_news = metadata.get("matched_news", 0)
            
            print(f"{label:23} | {events:6} | {matched_news:8} | {analysis_length:8}")
    
    def print_overall_comparison(self, all_results: List[Dict]):
        """ì „ì²´ ë¹„êµ ê²°ê³¼ ì¶œë ¥"""
        
        print("\n" + "="*70)
        print("ğŸ¯ ì „ì²´ ëª¨ë¸ ë¹„êµ ì¢…í•© ê²°ê³¼")
        print("="*70)
        
        # ì¡°í•©ë³„ ì´ì  ê³„ì‚°
        total_scores = {}
        
        for result in all_results:
            comparison = result.get("comparison", {})
            for combo, score in comparison.get("scores", {}).items():
                if combo not in total_scores:
                    total_scores[combo] = 0
                total_scores[combo] += score
        
        # í‰ê·  ì ìˆ˜ ê³„ì‚°
        num_cases = len(all_results)
        avg_scores = {k: v/num_cases for k, v in total_scores.items()}
        
        # ìˆœìœ„ ì¶œë ¥
        sorted_avg = sorted(avg_scores.items(), key=lambda x: x[1], reverse=True)
        
        print("\nğŸ† ìµœì¢… í‰ê·  ì ìˆ˜:")
        for combo, avg_score in sorted_avg:
            model, approach = combo.split("_", 1)
            label = f"{model.upper()} + {approach.replace('_', ' ').title()}"
            print(f"{label}: {avg_score:.1f}ì ")
        
        # ìŠ¹ì ë°œí‘œ
        if sorted_avg:
            winner_combo = sorted_avg[0][0]
            winner_model, winner_approach = winner_combo.split("_", 1)
            print(f"\nğŸ‰ ìµœê³  ì„±ëŠ¥ ì¡°í•©: {winner_model.upper()} + {winner_approach.replace('_', ' ').title()}")
    
    def calculate_comparison_statistics(self, results: List[Dict]) -> Dict:
        """ë¹„êµ í†µê³„ ê³„ì‚°"""
        
        stats = {
            "total_cases": len(results),
            "model_performance": {
                "gemini": {"wins": 0, "total_score": 0},
                "llama": {"wins": 0, "total_score": 0}
            },
            "approach_performance": {
                "standard_rag": {"wins": 0, "total_score": 0},
                "enhanced_crag": {"wins": 0, "total_score": 0}
            }
        }
        
        for result in results:
            comparison = result.get("comparison", {})
            if comparison.get("best_combination"):
                best = comparison["best_combination"]
                model, approach = best.split("_", 1)
                
                # ëª¨ë¸ë³„ ìŠ¹ë¦¬ ì¹´ìš´íŠ¸
                stats["model_performance"][model]["wins"] += 1
                
                # ì ‘ê·¼ë²•ë³„ ìŠ¹ë¦¬ ì¹´ìš´íŠ¸  
                stats["approach_performance"][approach]["wins"] += 1
            
            # ì ìˆ˜ ì§‘ê³„
            for combo, score in comparison.get("scores", {}).items():
                model, approach = combo.split("_", 1)
                stats["model_performance"][model]["total_score"] += score
                stats["approach_performance"][approach]["total_score"] += score
        
        return stats
    
    # ê¸°ì¡´ ë©”ì„œë“œë“¤ (ê°„ëµí™”ë¥¼ ìœ„í•´ ì£¼ìš” ë©”ì„œë“œë§Œ í¬í•¨)
    def robust_fetch_intraday_price(self, stock_code: str, date: str) -> pd.DataFrame:
        """ê°•ê±´í•œ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            from naver_finance_crawler import fetch_intraday_price
            df = fetch_intraday_price(stock_code, date)
            if len(df) > 0:
                return df
        except:
            pass
        return self.generate_realistic_mock_data(stock_code, date)
    
    def generate_realistic_mock_data(self, stock_code: str, date: str) -> pd.DataFrame:
        """ëª¨ì˜ ë°ì´í„° ìƒì„±"""
        base_prices = {
            "005930": 60000, "000660": 120000, "042700": 45000,
            "035420": 180000, "012450": 850000
        }
        base_price = base_prices.get(stock_code, 50000)
        
        start_time = datetime.strptime(f"{date} 09:00", "%Y-%m-%d %H:%M")
        times, prices, volumes = [], [], []
        current_price = base_price
        
        for i in range(390):
            current_time = start_time + timedelta(minutes=i)
            if 12 <= current_time.hour < 13:
                continue
                
            change_rate = random.gauss(0, 0.003)
            current_price *= (1 + change_rate)
            current_price = max(int(current_price), 1000)
            volume = random.randint(10000, 300000)
            
            times.append(current_time)
            prices.append(current_price)
            volumes.append(volume)
        
        # ì´ë²¤íŠ¸ ìƒì„±
        event_indices = random.sample(range(50, len(prices)-50), 3)
        for idx in event_indices:
            event_type = random.choice(['strong_up', 'strong_down'])
            multiplier = 1.002 if event_type == 'strong_up' else 0.998
            for j in range(idx, min(idx+30, len(prices))):
                prices[j] *= multiplier
                volumes[j] *= 1.5
        
        return pd.DataFrame({
            'datetime': times,
            'price': [int(p) for p in prices],
            'volume': volumes
        })
    
    def enhanced_detect_price_events(self, df: pd.DataFrame, threshold=0.006) -> pd.DataFrame:
        """í–¥ìƒëœ ì´ë²¤íŠ¸ ê°ì§€"""
        df = df.copy()
        df = df.sort_values("datetime").reset_index(drop=True)
        start_price = df.iloc[0]['price']
        
        df['pct_from_start'] = (df['price'] - start_price) / start_price
        df['pct_change'] = df['price'].pct_change()
        
        def detect_event_type(row, index):
            if abs(row['pct_from_start']) >= threshold:
                return "ìƒìŠ¹" if row['pct_from_start'] > 0 else "í•˜ë½"
            return None
        
        df['event_type'] = [detect_event_type(row, i) for i, row in df.iterrows()]
        events = df[df['event_type'].notnull()][['datetime', 'price', 'pct_from_start', 'event_type']]
        
        return events
    
    def intelligent_news_analysis(self, formatted_news: list, stock_name: str) -> list:
        """ì§€ëŠ¥í˜• ë‰´ìŠ¤ ë¶„ì„"""
        positive_keywords = ["ìƒìŠ¹", "í˜¸ì¬", "ì„±ì¥", "ìˆ˜ì£¼", "ê³„ì•½"]
        negative_keywords = ["í•˜ë½", "ì•…ì¬", "ê°ì†Œ", "ì†ì‹¤", "ìœ„í—˜"]
        
        analyzed_news = []
        for news in formatted_news:
            title = news['title'].lower()
            relevance_score = 0
            
            if stock_name.lower() in title:
                relevance_score += 10
            
            sentiment_score = 0
            for pos_word in positive_keywords:
                if pos_word in title:
                    sentiment_score += 1
            for neg_word in negative_keywords:
                if neg_word in title:
                    sentiment_score -= 1
            
            if relevance_score >= 2:
                analyzed_news.append({
                    **news,
                    'relevance_score': relevance_score,
                    'sentiment_score': sentiment_score,
                    'sentiment': 'positive' if sentiment_score > 0 else ('negative' if sentiment_score < 0 else 'neutral')
                })
        
        return analyzed_news
    
    def create_enhanced_comprehensive_analysis(self, events_df, matched_news_dict, matched_disclosures_dict, 
                                             stock_name: str, date: str) -> str:
        """CRAG íŠ¹í™” í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        event_summary = ""
        if len(events_df) > 0:
            event_summary = f"ğŸ“ˆ ê°ì§€ëœ ì´ë²¤íŠ¸ ({len(events_df)}ê°œ):\n"
            for _, event in events_df.iterrows():
                pct = event['pct_from_start'] * 100
                event_time = event['datetime'].strftime('%H:%M')
                event_summary += f"- {event_time}: {pct:+.2f}% {event['event_type']} (â‚©{event['price']:,})\n"
        else:
            event_summary = "ğŸ“ˆ ê°ì§€ëœ ì´ë²¤íŠ¸:\n- ì„ê³„ê°’ 0.6% ì´ìƒì˜ ì£¼ìš” ë³€ë™ì´ ì—†ëŠ” ì•ˆì •ì  ê±°ë˜ì¼\n"
        
        all_news = []
        for news_list in matched_news_dict.values():
            for news in news_list:
                if news['title'] not in [n['title'] for n in all_news]:
                    all_news.append(news)
        
        news_summary = ""
        if all_news:
            news_summary = f"ğŸ“° CRAG ì¸ê³¼ê´€ê³„ ë‰´ìŠ¤ ({len(all_news)}ê°œ):\n"
            for news in all_news[:3]:
                news_summary += f"- {news['title']}\n"
        else:
            news_summary = "ğŸ“° CRAG ì¸ê³¼ê´€ê³„ ë‰´ìŠ¤:\n- ì‹œê°„ì  ì„ í›„ê´€ê³„ë¥¼ ê°–ëŠ” ê´€ë ¨ ë‰´ìŠ¤ ì—†ìŒ\n"
        
        all_disclosures = []
        for disc_list in matched_disclosures_dict.values():
            all_disclosures.extend(disc_list)
        
        disclosure_summary = ""
        if all_disclosures:
            disclosure_summary = f"ğŸ“‹ CRAG ì¸ê³¼ê´€ê³„ ê³µì‹œ ({len(all_disclosures)}ê°œ):\n"
        else:
            disclosure_summary = "ğŸ“‹ CRAG ì¸ê³¼ê´€ê³„ ê³µì‹œ:\n- 72ì‹œê°„ ë‚´ ê´€ë ¨ ê³µì‹œì •ë³´ ì—†ìŒ\n"
        
        comprehensive_prompt = f"""[{date} {stock_name} ê°•í™”ëœ CRAG ë¶„ì„ ë¦¬í¬íŠ¸]

{event_summary}

{news_summary}

{disclosure_summary}

ğŸ§  **ê°•í™”ëœ CRAG íŠ¹í™” ë¶„ì„ ìš”ì²­:**

ë‹¤ìŒ ê´€ì ì—ì„œ Standard RAGë¥¼ ë›°ì–´ë„˜ëŠ” ì°¨ë³„í™”ëœ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”:

1. **ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ìš°ìˆ˜ì„±**: ì´ë²¤íŠ¸ "ì´ì „" ì •ë³´ë§Œ ì‚¬ìš©í•œ ì§„ì •í•œ ì›ì¸ ë¶„ì„
2. **CRAG ê³ ìœ  í†µì°°ë ¥**: ì‹œê°„ ìˆœì„œ ê¸°ë°˜ ìˆ¨ê²¨ì§„ íŒ¨í„´ ë°œêµ´
3. **ì˜ˆì¸¡ì  ê°€ì¹˜**: í–¥í›„ ìœ ì‚¬ ìƒí™© ì˜ˆì¸¡ì— í™œìš© ê°€ëŠ¥í•œ ì‹ í˜¸
4. **ì‹¤ì „ ì°¨ë³„í™”**: ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ê¸°ë°˜ì˜ êµ¬ì²´ì  íˆ¬ì ì „ëµ

ì „ë¬¸ì ì´ê³  ì‹¤ë¬´ì ì¸ ë¶„ì„ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        
        return comprehensive_prompt


# ì‹¤í–‰ í•¨ìˆ˜
def main():
    """ëª¨ë¸ ë¹„êµ í‰ê°€ ì‹¤í–‰"""
    
    print("ğŸš€ CRAG ì‹œìŠ¤í…œ ëª¨ë¸ ë¹„êµ í‰ê°€")
    print("ğŸ“Š Gemini vs LLaMA + Standard RAG vs Enhanced CRAG")
    print("="*70)
    
    # Groq API í‚¤ í™•ì¸
    groq_key = "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" #os.getenv("GROQ_API_KEY")
    
    if not groq_key or groq_key != "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":
        print("\nâš ï¸ GROQ_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("LLaMA ëª¨ë¸ ë¹„êµë¥¼ ìœ„í•´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¥´ì„¸ìš”:")
        print("1. https://console.groq.com ì—ì„œ ë¬´ë£Œ API í‚¤ ë°œê¸‰")
        print("2. export GROQ_API_KEY='your-api-key' ì‹¤í–‰")
        print("3. ë‹¤ì‹œ ì´ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰\n")
        
        response = input("Geminië§Œìœ¼ë¡œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if response.lower() != 'y':
            return
    
    # í‰ê°€ ì‹¤í–‰
    evaluator = ModelComparisonCRAGEvaluator()
    results = evaluator.run_model_comparison_evaluation()
    
    # ê²°ê³¼ ì €ì¥
    with open('model_comparison_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    # ë§ˆí¬ë‹¤ìš´ ìš”ì•½ ìƒì„±
    create_comparison_markdown(results)
    
    print("\nâœ… ëª¨ë¸ ë¹„êµ í‰ê°€ ì™„ë£Œ!")
    print("ğŸ“„ ê²°ê³¼ íŒŒì¼:")
    print("- model_comparison_results.json")
    print("- model_comparison_summary.md")


def create_comparison_markdown(results: Dict):
    """ë¹„êµ ê²°ê³¼ë¥¼ Markdownìœ¼ë¡œ ì €ì¥"""
    
    lines = []
    lines.append(f"# CRAG ì‹œìŠ¤í…œ ëª¨ë¸ ë¹„êµ ê²°ê³¼ ({datetime.now().strftime('%Y-%m-%d')})\n")
    lines.append("## í‰ê°€ ê°œìš”\n")
    lines.append("- **ëª¨ë¸**: Gemini vs LLaMA")
    lines.append("- **ì ‘ê·¼ë²•**: Standard RAG vs Enhanced CRAG")
    lines.append("- **ì¡°í•©**: 4ê°€ì§€ (2x2 ë§¤íŠ¸ë¦­ìŠ¤)\n")
    
    summary = results.get("summary", {})
    
    lines.append("\n## ëª¨ë¸ë³„ ì„±ëŠ¥\n")
    lines.append("| ëª¨ë¸ | ìŠ¹ë¦¬ íšŸìˆ˜ | ì´ ì ìˆ˜ |")
    lines.append("|------|----------|---------|")
    
    for model in ["gemini", "llama"]:
        perf = summary.get("model_performance", {}).get(model, {})
        lines.append(f"| {model.upper()} | {perf.get('wins', 0)} | {perf.get('total_score', 0)} |")
    
    lines.append("\n## ì ‘ê·¼ë²•ë³„ ì„±ëŠ¥\n")
    lines.append("| ì ‘ê·¼ë²• | ìŠ¹ë¦¬ íšŸìˆ˜ | ì´ ì ìˆ˜ |")
    lines.append("|--------|----------|---------|")
    
    for approach in ["standard_rag", "enhanced_crag"]:
        perf = summary.get("approach_performance", {}).get(approach, {})
        label = approach.replace("_", " ").title()
        lines.append(f"| {label} | {perf.get('wins', 0)} | {perf.get('total_score', 0)} |")
    
    lines.append("\n## ì£¼ìš” ë°œê²¬ì‚¬í•­\n")
    lines.append("1. **ìµœê³  ì„±ëŠ¥ ì¡°í•©**: í‰ê°€ ê²°ê³¼ì— ë”°ë¼ ê²°ì •")
    lines.append("2. **ëª¨ë¸ íŠ¹ì„±**: Geminiì™€ LLaMAì˜ ê°•ì  ë¹„êµ")
    lines.append("3. **CRAG íš¨ê³¼**: ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë¶„ì„ì˜ ê°€ì¹˜")
    
    with open('model_comparison_summary.md', 'w', encoding='utf-8') as f:
        f.write("\n".join(lines))


if __name__ == "__main__":
    main()