
import requests
import json
import time
from datetime import datetime, timedelta
from typing import List, Dict, Tuple
import re
from urllib.parse import quote
import os

class EnhancedNewsCollector:
    """í–¥ìƒëœ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, client_id: str, client_secret: str):
        self.client_id = client_id
        self.client_secret = client_secret
        self.headers = {
            "X-Naver-Client-Id": client_id,
            "X-Naver-Client-Secret": client_secret
        }
        self.base_url = "https://openapi.naver.com/v1/search/news.json"
        
        # ì¢…ëª©ë³„ í‚¤ì›Œë“œ ë§¤í•‘ (ê´€ë ¨ì„± í–¥ìƒ)
        self.stock_keywords = {
            "ì‚¼ì„±ì „ì": ["ì‚¼ì„±ì „ì", "ì‚¼ì „", "ë°˜ë„ì²´", "ê°¤ëŸ­ì‹œ", "ì—‘ì‹œë…¸ìŠ¤", "íŒŒìš´ë“œë¦¬"],
            "SKí•˜ì´ë‹‰ìŠ¤": ["SKí•˜ì´ë‹‰ìŠ¤", "í•˜ì´ë‹‰ìŠ¤", "Dë¨", "ë‚¸ë“œ", "ë©”ëª¨ë¦¬ë°˜ë„ì²´"],
            "LGì—ë„ˆì§€ì†”ë£¨ì…˜": ["LGì—ë„ˆì§€ì†”ë£¨ì…˜", "LGì—ë„ˆì§€", "ë°°í„°ë¦¬", "ì´ì°¨ì „ì§€", "ì „ê¸°ì°¨ë°°í„°ë¦¬"],
            "í˜„ëŒ€ì°¨": ["í˜„ëŒ€ìë™ì°¨", "í˜„ëŒ€ì°¨", "ì•„ì´ì˜¤ë‹‰", "ì œë„¤ì‹œìŠ¤", "ì „ê¸°ì°¨"],
            "NAVER": ["ë„¤ì´ë²„", "NAVER", "ë¼ì¸", "ì›¹íˆ°", "í´ë¡œë°”"],
            "ì¹´ì¹´ì˜¤": ["ì¹´ì¹´ì˜¤", "kakao", "ì¹´ì¹´ì˜¤í†¡", "ì¹´ì¹´ì˜¤í˜ì´", "ì¹´ì¹´ì˜¤ë±…í¬"],
            "ë°”ì´ì˜¤": ["ë°”ì´ì˜¤", "ì‹ ì•½", "ì„ìƒ", "FDA", "í’ˆëª©í—ˆê°€"],
            "ì—”í„°": ["ì—”í„°í…Œì¸ë¨¼íŠ¸", "ì—”í„°", "ì•„ì´ëŒ", "ì½˜í…ì¸ ", "IP"]
        }
        
        # ë‰´ìŠ¤ í’ˆì§ˆ í•„í„°ë§ í‚¤ì›Œë“œ
        self.quality_keywords = {
            "positive": ["ìƒìŠ¹", "ê¸‰ë“±", "í˜¸ì¬", "ì‹ ê³ ê°€", "ì„±ì¥", "ìˆ˜ì£¼", "ê³„ì•½", "ìŠ¹ì¸", "ì¶œì‹œ"],
            "negative": ["í•˜ë½", "ê¸‰ë½", "ì•…ì¬", "ì €ê°€", "ê°ì†Œ", "ì†ì‹¤", "ë¦¬ì½œ", "ì†Œì†¡", "ì§€ì—°"],
            "neutral": ["ì „ë§", "ë¶„ì„", "í‰ê°€", "ì˜ˆìƒ", "ê³„íš", "ê²€í† ", "ì¶”ì§„", "í˜‘ì˜"]
        }
    
    def search_news_multi_strategy(self, stock_name: str, date: str, 
                                 days_before: int = 3, days_after: int = 1) -> List[Dict]:
        """
        ë‹¤ì–‘í•œ ì „ëµìœ¼ë¡œ ë‰´ìŠ¤ ê²€ìƒ‰
        
        Args:
            stock_name: ì¢…ëª©ëª…
            date: ê¸°ì¤€ ë‚ ì§œ (YYYY-MM-DD)
            days_before: ë©°ì¹  ì „ê¹Œì§€ ê²€ìƒ‰
            days_after: ë©°ì¹  í›„ê¹Œì§€ ê²€ìƒ‰
            
        Returns:
            ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        all_news = []
        seen_titles = set()  # ì¤‘ë³µ ì œê±°ìš©
        
        # ë‚ ì§œ ë²”ìœ„ ì„¤ì •
        base_date = datetime.strptime(date, "%Y-%m-%d")
        start_date = base_date - timedelta(days=days_before)
        end_date = base_date + timedelta(days=days_after)
        
        # ì „ëµ 1: ì¢…ëª©ëª… ì§ì ‘ ê²€ìƒ‰
        print(f"ğŸ” ì „ëµ 1: '{stock_name}' ì§ì ‘ ê²€ìƒ‰")
        news1 = self._search_news(
            query=stock_name,
            start_date=start_date.strftime("%Y-%m-%d"),
            end_date=end_date.strftime("%Y-%m-%d"),
            display=50
        )
        all_news.extend(news1)
        
        # ì „ëµ 2: ì¢…ëª© ê´€ë ¨ í‚¤ì›Œë“œ ì¡°í•© ê²€ìƒ‰
        related_keywords = self._get_related_keywords(stock_name)
        if related_keywords:
            for keyword in related_keywords[:3]:  # ìƒìœ„ 3ê°œ í‚¤ì›Œë“œ
                if keyword != stock_name:  # ì¤‘ë³µ ë°©ì§€
                    print(f"ğŸ” ì „ëµ 2: '{stock_name} {keyword}' ì¡°í•© ê²€ìƒ‰")
                    news2 = self._search_news(
                        query=f"{stock_name} {keyword}",
                        start_date=start_date.strftime("%Y-%m-%d"),
                        end_date=end_date.strftime("%Y-%m-%d"),
                        display=30
                    )
                    all_news.extend(news2)
                    time.sleep(0.1)  # API ì œí•œ ë°©ì§€
        
        # ì „ëµ 3: íŠ¹ì • ë‚ ì§œ ì§‘ì¤‘ ê²€ìƒ‰
        print(f"ğŸ” ì „ëµ 3: {date} ë‚ ì§œ ì§‘ì¤‘ ê²€ìƒ‰")
        news3 = self._search_news(
            query=stock_name,
            start_date=date,
            end_date=date,
            display=30,
            sort="sim"  # ì •í™•ë„ìˆœ
        )
        all_news.extend(news3)
        
        # ì „ëµ 4: ì£¼ìš” ì´ë²¤íŠ¸ í‚¤ì›Œë“œ ì¡°í•©
        event_keywords = ["ì‹¤ì ", "ê³µì‹œ", "ë°œí‘œ", "ê³„ì•½", "ìˆ˜ì£¼"]
        for event_keyword in event_keywords[:2]:
            print(f"ğŸ” ì „ëµ 4: '{stock_name} {event_keyword}' ì´ë²¤íŠ¸ ê²€ìƒ‰")
            news4 = self._search_news(
                query=f"{stock_name} {event_keyword}",
                start_date=start_date.strftime("%Y-%m-%d"),
                end_date=end_date.strftime("%Y-%m-%d"),
                display=20
            )
            all_news.extend(news4)
            time.sleep(0.1)
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        unique_news = []
        for news in all_news:
            if news['title'] not in seen_titles:
                seen_titles.add(news['title'])
                unique_news.append(news)
        
        # ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬
        scored_news = self._calculate_relevance_scores(unique_news, stock_name, date)
        scored_news.sort(key=lambda x: x['relevance_score'], reverse=True)
        
        print(f"âœ… ì´ {len(scored_news)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
        return scored_news
    
    def _search_news(self, query: str, start_date: str, end_date: str, 
                    display: int = 50, sort: str = "date") -> List[Dict]:
        """
        ë„¤ì´ë²„ ë‰´ìŠ¤ API í˜¸ì¶œ
        
        Args:
            query: ê²€ìƒ‰ì–´
            start_date: ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD) - ì°¸ê³ ìš©
            end_date: ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD) - ì°¸ê³ ìš©
            display: ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ (ìµœëŒ€ 100)
            sort: ì •ë ¬ ë°©ì‹ (date: ë‚ ì§œìˆœ, sim: ì •í™•ë„ìˆœ)
        """
        news_items = []
        
        params = {
            "query": query,
            "display": min(display, 100),
            "start": 1,
            "sort": sort
        }
        
        print(f"  API í˜¸ì¶œ: {query} (display={params['display']})")
        
        try:
            response = requests.get(self.base_url, headers=self.headers, params=params)
            response.raise_for_status()
            
            data = response.json()
            items = data.get("items", [])
            
            print(f"  API ì‘ë‹µ: {len(items)}ê°œ í•­ëª©")
            
            # ë‚ ì§œ í•„í„°ë§ ê¸°ì¤€ ì„¤ì •
            start_datetime = datetime.strptime(start_date + " 00:00:00", "%Y-%m-%d %H:%M:%S")
            end_datetime = datetime.strptime(end_date + " 23:59:59", "%Y-%m-%d %H:%M:%S")
            
            for item in items:
                # ë‚ ì§œ íŒŒì‹±
                pub_date = self._parse_date(item.get("pubDate", ""))
                
                if pub_date:
                    try:
                        pub_datetime = datetime.strptime(pub_date, "%Y-%m-%d %H:%M:%S")
                        
                        # ë‚ ì§œ í•„í„°ë§ (ì„ íƒì )
                        # ë„¤ì´ë²„ APIëŠ” ìµœì‹  ë‰´ìŠ¤ë¶€í„° ì œê³µí•˜ë¯€ë¡œ, ë„ˆë¬´ ì˜¤ë˜ëœ ë‰´ìŠ¤ë§Œ ì œì™¸
                        days_diff = abs((pub_datetime - start_datetime).days)
                        if days_diff <= 7:  # 7ì¼ ì´ë‚´ ë‰´ìŠ¤ë§Œ
                            news_item = {
                                "title": self._clean_html(item.get("title", "")),
                                "link": item.get("link", ""),
                                "description": self._clean_html(item.get("description", "")),
                                "pubDate": pub_date,
                                "originallink": item.get("originallink", "")
                            }
                            news_items.append(news_item)
                    except Exception as e:
                        print(f"  ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜: {e}")
                        # ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨í•´ë„ ë‰´ìŠ¤ëŠ” í¬í•¨
                        news_item = {
                            "title": self._clean_html(item.get("title", "")),
                            "link": item.get("link", ""),
                            "description": self._clean_html(item.get("description", "")),
                            "pubDate": item.get("pubDate", ""),
                            "originallink": item.get("originallink", "")
                        }
                        news_items.append(news_item)
            
            print(f"  í•„í„°ë§ í›„: {len(news_items)}ê°œ ë‰´ìŠ¤")
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ API ìš”ì²­ ì˜¤ë¥˜: {e}")
            if hasattr(e, 'response') and e.response:
                print(f"   ìƒíƒœ ì½”ë“œ: {e.response.status_code}")
                print(f"   ì‘ë‹µ ë‚´ìš©: {e.response.text[:200]}")
        except Exception as e:
            print(f"âŒ ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
        
        return news_items
    
    def _get_related_keywords(self, stock_name: str) -> List[str]:
        """ì¢…ëª©ëª…ê³¼ ê´€ë ¨ëœ í‚¤ì›Œë“œ ë°˜í™˜"""
        # ì§ì ‘ ë§¤ì¹­
        if stock_name in self.stock_keywords:
            return self.stock_keywords[stock_name]
        
        # ë¶€ë¶„ ë§¤ì¹­
        for key, keywords in self.stock_keywords.items():
            if key in stock_name or stock_name in key:
                return keywords
        
        # ì—…ì¢…ë³„ í‚¤ì›Œë“œ
        if "ë°”ì´ì˜¤" in stock_name or "ì œì•½" in stock_name:
            return self.stock_keywords.get("ë°”ì´ì˜¤", [])
        elif "ì—”í„°" in stock_name:
            return self.stock_keywords.get("ì—”í„°", [])
        
        return []
    
    def _calculate_relevance_scores(self, news_list: List[Dict], 
                                  stock_name: str, target_date: str) -> List[Dict]:
        """
        ë‰´ìŠ¤ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
        
        ì ìˆ˜ ê¸°ì¤€:
        - ì œëª©ì— ì¢…ëª©ëª… í¬í•¨: +10ì 
        - ë³¸ë¬¸ì— ì¢…ëª©ëª… í¬í•¨: +5ì 
        - ë‚ ì§œ ê·¼ì ‘ì„±: ìµœëŒ€ 10ì 
        - í’ˆì§ˆ í‚¤ì›Œë“œ: +3ì ì”©
        - ê´€ë ¨ í‚¤ì›Œë“œ: +2ì ì”©
        """
        target_datetime = datetime.strptime(target_date, "%Y-%m-%d")
        related_keywords = self._get_related_keywords(stock_name)
        
        for news in news_list:
            score = 0
            
            title = news.get("title", "").lower()
            description = news.get("description", "").lower()
            combined_text = title + " " + description
            
            # 1. ì¢…ëª©ëª… í¬í•¨ ì—¬ë¶€
            if stock_name.lower() in title:
                score += 10
            if stock_name.lower() in description:
                score += 5
            
            # 2. ë‚ ì§œ ê·¼ì ‘ì„± (ìµœëŒ€ 10ì )
            news_date = datetime.strptime(news["pubDate"], "%Y-%m-%d %H:%M:%S")
            date_diff = abs((news_date - target_datetime).days)
            date_score = max(0, 10 - date_diff * 2)
            score += date_score
            
            # 3. í’ˆì§ˆ í‚¤ì›Œë“œ
            for category, keywords in self.quality_keywords.items():
                for keyword in keywords:
                    if keyword in combined_text:
                        score += 3
            
            # 4. ê´€ë ¨ í‚¤ì›Œë“œ
            for keyword in related_keywords:
                if keyword.lower() in combined_text:
                    score += 2
            
            # 5. ë¶€ì •ì  ì‹ í˜¸ (ê´‘ê³ , í™ë³´ì„±)
            if any(word in title for word in ["ê´‘ê³ ", "ì œê³µ", "ë³´ë„ìë£Œ"]):
                score -= 5
            
            news["relevance_score"] = score
            news["date_diff"] = date_diff
        
        return news_list
    
    def _parse_date(self, date_str: str) -> str:
        """ë„¤ì´ë²„ API ë‚ ì§œ í˜•ì‹ íŒŒì‹±"""
        try:
            # ì˜ˆ: "Mon, 10 Jun 2024 15:30:00 +0900"
            from email.utils import parsedate_to_datetime
            dt = parsedate_to_datetime(date_str)
            return dt.strftime("%Y-%m-%d %H:%M:%S")
        except:
            return ""
    
    def _clean_html(self, text: str) -> str:
        """HTML íƒœê·¸ ì œê±°"""
        # <b>, </b> ë“± íƒœê·¸ ì œê±°
        text = re.sub('<.*?>', '', text)
        # &quot; ë“± HTML ì—”í‹°í‹° ë³€í™˜
        text = text.replace('&quot;', '"').replace('&amp;', '&')
        text = text.replace('&lt;', '<').replace('&gt;', '>')
        return text.strip()
    
    def analyze_news_impact(self, news_list: List[Dict], stock_name: str) -> Dict:
        """
        ë‰´ìŠ¤ ì˜í–¥ë ¥ ë¶„ì„
        
        Returns:
            {
                "positive_count": int,
                "negative_count": int,
                "neutral_count": int,
                "key_events": List[Dict],
                "sentiment_score": float,
                "impact_summary": str
            }
        """
        positive_count = 0
        negative_count = 0
        neutral_count = 0
        key_events = []
        
        for news in news_list[:20]:  # ìƒìœ„ 20ê°œ ë¶„ì„
            title = news.get("title", "").lower()
            description = news.get("description", "").lower()
            combined = title + " " + description
            
            # ê°ì„± ë¶„ì„
            pos_score = sum(1 for word in self.quality_keywords["positive"] if word in combined)
            neg_score = sum(1 for word in self.quality_keywords["negative"] if word in combined)
            
            if pos_score > neg_score:
                positive_count += 1
                sentiment = "positive"
            elif neg_score > pos_score:
                negative_count += 1
                sentiment = "negative"
            else:
                neutral_count += 1
                sentiment = "neutral"
            
            # ì£¼ìš” ì´ë²¤íŠ¸ ì¶”ì¶œ
            if news.get("relevance_score", 0) >= 15:  # ê³ ê´€ë ¨ì„± ë‰´ìŠ¤
                key_events.append({
                    "title": news["title"],
                    "date": news["pubDate"],
                    "sentiment": sentiment,
                    "relevance_score": news.get("relevance_score", 0)
                })
        
        # ì¢…í•© ê°ì„± ì ìˆ˜ (-1 ~ 1)
        total_news = positive_count + negative_count + neutral_count
        if total_news > 0:
            sentiment_score = (positive_count - negative_count) / total_news
        else:
            sentiment_score = 0
        
        # ì˜í–¥ë ¥ ìš”ì•½
        if sentiment_score > 0.3:
            impact_summary = f"{stock_name}ì— ëŒ€í•œ ê¸ì •ì ì¸ ë‰´ìŠ¤ê°€ ìš°ì„¸í•©ë‹ˆë‹¤. í˜¸ì¬ ì¤‘ì‹¬ì˜ ë³´ë„ê°€ ì´ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤."
        elif sentiment_score < -0.3:
            impact_summary = f"{stock_name}ì— ëŒ€í•œ ë¶€ì •ì ì¸ ë‰´ìŠ¤ê°€ ë§ìŠµë‹ˆë‹¤. íˆ¬ì ì‹¬ë¦¬ì— ì•…ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        else:
            impact_summary = f"{stock_name} ê´€ë ¨ ë‰´ìŠ¤ëŠ” ì¤‘ë¦½ì ì´ê±°ë‚˜ í˜¼ì¬ëœ ìƒí™©ì…ë‹ˆë‹¤."
        
        return {
            "positive_count": positive_count,
            "negative_count": negative_count,
            "neutral_count": neutral_count,
            "key_events": key_events[:5],  # ìƒìœ„ 5ê°œ
            "sentiment_score": round(sentiment_score, 3),
            "impact_summary": impact_summary,
            "total_analyzed": total_news
        }
    
    def get_competitor_news(self, stock_name: str, date: str) -> List[Dict]:
        """ê²½ìŸì‚¬ ê´€ë ¨ ë‰´ìŠ¤ë„ í•¨ê»˜ ìˆ˜ì§‘"""
        competitors = {
            "ì‚¼ì„±ì „ì": ["SKí•˜ì´ë‹‰ìŠ¤", "ì¸í…”", "TSMC"],
            "SKí•˜ì´ë‹‰ìŠ¤": ["ì‚¼ì„±ì „ì", "ë§ˆì´í¬ë¡ ", "ì›¨ìŠ¤í„´ë””ì§€í„¸"],
            "LGì—ë„ˆì§€ì†”ë£¨ì…˜": ["ì‚¼ì„±SDI", "SKì˜¨", "CATL"],
            "í˜„ëŒ€ì°¨": ["ê¸°ì•„", "í…ŒìŠ¬ë¼", "í­ìŠ¤ë°”ê²"],
            "NAVER": ["ì¹´ì¹´ì˜¤", "êµ¬ê¸€", "ì¿ íŒ¡"],
            "ì¹´ì¹´ì˜¤": ["ë„¤ì´ë²„", "ë¼ì¸", "ì¿ íŒ¡"]
        }
        
        competitor_news = []
        if stock_name in competitors:
            print(f"\nğŸ¢ ê²½ìŸì‚¬ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
            for competitor in competitors[stock_name][:2]:  # ìƒìœ„ 2ê°œ ê²½ìŸì‚¬
                news = self._search_news(
                    query=competitor,
                    start_date=date,
                    end_date=date,
                    display=10
                )
                for item in news:
                    item["competitor"] = competitor
                    item["original_stock"] = stock_name
                competitor_news.extend(news)
        
        return competitor_news


# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸
def test_enhanced_news_collector():
    """í–¥ìƒëœ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° í…ŒìŠ¤íŠ¸"""
    
    # API í‚¤ ì„¤ì • (ì‹¤ì œ ì‚¬ìš© ì‹œ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
    client_id = os.getenv("NAVER_CLIENT_ID", "JEuS9xkuWGpP40lsI9Kz")
    client_secret = os.getenv("NAVER_CLIENT_SECRET", "I6nujCm0xF")
    
    collector = EnhancedNewsCollector(client_id, client_secret)
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    test_cases = [
        ("ì‚¼ì„±ì „ì", "2024-06-10"),
        ("SKí•˜ì´ë‹‰ìŠ¤", "2024-06-10"),
        ("LGì—ë„ˆì§€ì†”ë£¨ì…˜", "2024-06-10")
    ]
    
    for stock_name, date in test_cases:
        print(f"\n{'='*70}")
        print(f"ğŸ“Š {stock_name} - {date} ë‰´ìŠ¤ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸")
        print(f"{'='*70}")
        
        # ë‹¤ì¤‘ ì „ëµ ë‰´ìŠ¤ ìˆ˜ì§‘
        news_list = collector.search_news_multi_strategy(
            stock_name=stock_name,
            date=date,
            days_before=3,
            days_after=0
        )
        
        print(f"\nğŸ“° ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ìƒìœ„ 10ê°œ:")
        for i, news in enumerate(news_list[:10], 1):
            print(f"{i}. [{news['relevance_score']}ì ] {news['title']}")
            print(f"   ë‚ ì§œ: {news['pubDate']} | ì°¨ì´: {news.get('date_diff', 0)}ì¼")
        
        # ì˜í–¥ë ¥ ë¶„ì„
        impact_analysis = collector.analyze_news_impact(news_list, stock_name)
        print(f"\nğŸ“ˆ ë‰´ìŠ¤ ì˜í–¥ë ¥ ë¶„ì„:")
        print(f"- ê¸ì •: {impact_analysis['positive_count']}ê°œ")
        print(f"- ë¶€ì •: {impact_analysis['negative_count']}ê°œ")
        print(f"- ì¤‘ë¦½: {impact_analysis['neutral_count']}ê°œ")
        print(f"- ê°ì„±ì ìˆ˜: {impact_analysis['sentiment_score']}")
        print(f"- ìš”ì•½: {impact_analysis['impact_summary']}")
        
        # ì£¼ìš” ì´ë²¤íŠ¸
        if impact_analysis['key_events']:
            print(f"\nğŸ¯ ì£¼ìš” ì´ë²¤íŠ¸:")
            for event in impact_analysis['key_events']:
                print(f"- {event['title']} ({event['sentiment']})")
        
        # ê²½ìŸì‚¬ ë‰´ìŠ¤
        competitor_news = collector.get_competitor_news(stock_name, date)
        if competitor_news:
            print(f"\nğŸ¢ ê²½ìŸì‚¬ ë‰´ìŠ¤:")
            for news in competitor_news[:5]:
                print(f"- [{news['competitor']}] {news['title']}")
        
        time.sleep(1)  # API ì œí•œ ë°©ì§€


if __name__ == "__main__":
    print("ğŸš€ í–¥ìƒëœ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("="*70)
    
    test_enhanced_news_collector()