from slack_sender import send_to_slack
from llm_reporter import get_llm_report
from naver_finance_crawler import fetch_kospi_daily, fetch_sector_etf_daily,fetch_industry_info_by_stock_code
from news_api_caller import NaverNewsSearcher, search_news_advanced, format_news_data, match_news_before_events
from seibro_disclosure_scraper import fetch_disclosures_with_fallback, match_disclosures_before_events
import pandas as pd
import os
import requests
from datetime import datetime, timedelta
import random

def get_stock_database():
    """ì¢…ëª© ë°ì´í„°ë² ì´ìŠ¤"""
    return {
        "ì‚¼ì„±ì „ì": ("005930", "ì‚¼ì„±ì „ì"), "skí•˜ì´ë‹‰ìŠ¤": ("000660", "SKí•˜ì´ë‹‰ìŠ¤"),
        "ë„¤ì´ë²„": ("035420", "NAVER"), "ì¹´ì¹´ì˜¤": ("035720", "ì¹´ì¹´ì˜¤"),
        "lgì „ì": ("066570", "LGì „ì"), "í˜„ëŒ€ì°¨": ("005380", "í˜„ëŒ€ì°¨"),
        "ê¸°ì•„": ("000270", "ê¸°ì•„"), "í¬ìŠ¤ì½”í™€ë”©ìŠ¤": ("005490", "POSCOí™€ë”©ìŠ¤"),
        "ì‚¼ì„±sdi": ("006400", "ì‚¼ì„±SDI"), "lgí™”í•™": ("051910", "LGí™”í•™"),
        "ì…€íŠ¸ë¦¬ì˜¨": ("068270", "ì…€íŠ¸ë¦¬ì˜¨"), "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤": ("207940", "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤"),
        "í˜„ëŒ€ëª¨ë¹„ìŠ¤": ("012330", "í˜„ëŒ€ëª¨ë¹„ìŠ¤"), "kbê¸ˆìœµ": ("105560", "KBê¸ˆìœµ"),
        "ì‹ í•œì§€ì£¼": ("055550", "ì‹ í•œì§€ì£¼"), "í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤": ("012450", "í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤"),
        "í•œí™”ì—ì–´ë¡œ": ("012450", "í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤"), "í•œí™”": ("000880", "í•œí™”"),
        "ëŒ€í•œí•­ê³µ": ("003490", "ëŒ€í•œí•­ê³µ"), "í•œí™”ì‹œìŠ¤í…œ": ("272210", "í•œí™”ì‹œìŠ¤í…œ"),
        "í•œë¯¸ë°˜ë„ì²´": ("042700", "í•œë¯¸ë°˜ë„ì²´"), "ì›ìµiqe": ("090350", "ì›ìµIQE"),
        "í…ŒìŠ¤": ("095610", "í…ŒìŠ¤"), "ë™ì§„ì„ë¯¸ì¼": ("005290", "ë™ì§„ì„ë¯¸ì¼"),
        "ì†”ë¸Œë ˆì¸": ("357780", "ì†”ë¸Œë ˆì¸"), "ì‹¤ë¦¬ì½˜ì›ìŠ¤": ("108320", "ì‹¤ë¦¬ì½˜ì›ìŠ¤"),
        "ì—”ì”¨ì†Œí”„íŠ¸": ("036570", "ì—”ì”¨ì†Œí”„íŠ¸"), "ë„·ë§ˆë¸”": ("251270", "ë„·ë§ˆë¸”"),
        "í¬ë˜í”„í†¤": ("259960", "í¬ë˜í”„í†¤"), "í•˜ì´ë¸Œ": ("352820", "í•˜ì´ë¸Œ"),
        "ì•„ëª¨ë ˆí¼ì‹œí”½": ("090430", "ì•„ëª¨ë ˆí¼ì‹œí”½"), "lgìƒí™œê±´ê°•": ("051900", "LGìƒí™œê±´ê°•"),
        "kt": ("030200", "KT"), "skt": ("017670", "SKí…”ë ˆì½¤"),
        "í•œêµ­ì „ë ¥": ("015760", "í•œêµ­ì „ë ¥ê³µì‚¬"), "ë†ì‹¬": ("004370", "ë†ì‹¬")
    }

def robust_fetch_intraday_price(stock_code: str, date: str) -> pd.DataFrame:
    """ê°•ê±´í•œ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘"""
    try:
        from naver_finance_crawler import fetch_intraday_price
        df = fetch_intraday_price(stock_code, date)
        if len(df) > 0:
            print(f"âœ… ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ {len(df)}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ")
            return df
    except Exception as e:
        print(f"âš ï¸ ë„¤ì´ë²„ ê¸ˆìœµ ì‹¤íŒ¨: {e}")
    
    print("ğŸ”„ í˜„ì‹¤ì ì¸ ëª¨ì˜ ë°ì´í„° ìƒì„±ìœ¼ë¡œ ëŒ€ì²´")
    return generate_realistic_mock_data(stock_code, date)

def generate_realistic_mock_data(stock_code: str, date: str) -> pd.DataFrame:
    """í˜„ì‹¤ì ì¸ ëª¨ì˜ ë°ì´í„° ìƒì„±"""
    base_prices = {
        "005930": 60000, "000660": 120000, "042700": 45000,
        "035420": 180000, "012450": 850000
    }
    base_price = base_prices.get(stock_code, 50000)
    
    start_time = datetime.strptime(f"{date} 09:00", "%Y-%m-%d %H:%M")
    times, prices, volumes = [], [], []
    current_price = base_price
    
    for i in range(390):
        current_time = start_time + timedelta(minutes=i)
        if 12 <= current_time.hour < 13:
            continue
            
        change_rate = random.gauss(0, 0.003)
        current_price *= (1 + change_rate)
        current_price = max(int(current_price), 1000)
        volume = random.randint(10000, 300000)
        
        times.append(current_time)
        prices.append(current_price)
        volumes.append(volume)
    
    # ì˜ë„ì  ì´ë²¤íŠ¸ ìƒì„±
    event_indices = random.sample(range(50, len(prices)-50), 3)
    for idx in event_indices:
        event_type = random.choice(['strong_up', 'strong_down'])
        multiplier = 1.002 if event_type == 'strong_up' else 0.998
        for j in range(idx, min(idx+30, len(prices))):
            prices[j] *= multiplier
            volumes[j] *= 1.5
    
    df = pd.DataFrame({
        'datetime': times,
        'price': [int(p) for p in prices],
        'volume': volumes
    })
    
    print(f"ğŸ“Š í˜„ì‹¤ì  ëª¨ì˜ ë°ì´í„° ìƒì„±: {len(df)}ê°œ ì‹œì , ì´ë²¤íŠ¸ {len(event_indices)}ê°œ í¬í•¨")
    return df

def enhanced_detect_price_events_by_day(df: pd.DataFrame, threshold=0.006) -> pd.DataFrame:
    """í–¥ìƒëœ ì´ë²¤íŠ¸ ê°ì§€"""
    df = df.copy().sort_values("datetime").reset_index(drop=True)
    start_price = df.iloc[0]['price']
    df['pct_from_start'] = (df['price'] - start_price) / start_price
    df['pct_change'] = df['price'].pct_change()
    df['ma_20'] = df['price'].rolling(window=20, min_periods=1).mean()
    df['pct_from_ma'] = (df['price'] - df['ma_20']) / df['ma_20']
    
    def detect_event_type(row, index):
        if abs(row['pct_from_start']) >= threshold:
            return "ìƒìŠ¹" if row['pct_from_start'] > 0 else "í•˜ë½"
        
        if index >= 10:
            recent_change = (row['price'] - df.iloc[index-10]['price']) / df.iloc[index-10]['price']
            if abs(recent_change) >= 0.008:
                return "ê¸‰ìƒìŠ¹" if recent_change > 0 else "ê¸‰í•˜ë½"
        
        if index > 0 and df.iloc[index-1]['volume'] > 0:
            volume_ratio = row['volume'] / df.iloc[index-1]['volume']
            if volume_ratio >= 1.8 and abs(row['pct_change']) >= 0.003:
                return "ê±°ë˜ëŸ‰ê¸‰ì¦ìƒìŠ¹" if row['pct_change'] > 0 else "ê±°ë˜ëŸ‰ê¸‰ì¦í•˜ë½"
        
        if not pd.isna(row['pct_from_ma']) and abs(row['pct_from_ma']) >= 0.005:
            return "MAìƒìŠ¹ì´íƒˆ" if row['pct_from_ma'] > 0 else "MAí•˜ë½ì´íƒˆ"
        
        return None
    
    df['event_type'] = [detect_event_type(row, i) for i, row in df.iterrows()]
    events = df[df['event_type'].notnull()][['datetime', 'price', 'pct_from_start', 'event_type']]
    
    print(f"ğŸ¯ í–¥ìƒëœ ì´ë²¤íŠ¸ ê°ì§€: {len(events)}ê°œ (ì„ê³„ê°’: {threshold*100:.1f}%)")
    return events

def intelligent_news_analysis(formatted_news: list, stock_name: str) -> list:
    """ì§€ëŠ¥í˜• ë‰´ìŠ¤ ë¶„ì„"""
    positive_keywords = ["ìƒìŠ¹", "í˜¸ì¬", "ì„±ì¥", "ìˆ˜ì£¼", "ê³„ì•½", "íˆ¬ì", "í™•ëŒ€", "ê°œì„ "]
    negative_keywords = ["í•˜ë½", "ì•…ì¬", "ê°ì†Œ", "ì†ì‹¤", "ìœ„í—˜", "ìš°ë ¤", "ë¶€ì •", "ì·¨ì†Œ"]
    
    industry_keywords = {
        "ì‚¼ì„±ì „ì": ["ë°˜ë„ì²´", "ë©”ëª¨ë¦¬", "ìŠ¤ë§ˆíŠ¸í°", "ê°¤ëŸ­ì‹œ"],
        "SKí•˜ì´ë‹‰ìŠ¤": ["ë°˜ë„ì²´", "ë©”ëª¨ë¦¬", "hbm", "dram"],
        "í•œë¯¸ë°˜ë„ì²´": ["ë°˜ë„ì²´", "ì¥ë¹„", "ì›¨ì´í¼"],
        "NAVER": ["ì¸í„°ë„·", "ê²€ìƒ‰", "ai", "ì›¹íˆ°"],
        "í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤": ["ë°©ì‚°", "í•­ê³µ", "ìš°ì£¼", "ë¡œì¼“"]
    }
    
    stock_keywords = industry_keywords.get(stock_name, ["ì£¼ì‹", "íˆ¬ì"])
    analyzed_news = []
    
    for news in formatted_news:
        title = news['title'].lower()
        stock_lower = stock_name.lower()
        
        relevance_score = 0
        if stock_lower in title:
            relevance_score += 10
        for keyword in stock_keywords:
            if keyword in title:
                relevance_score += 3
        
        sentiment_score = 0
        for pos_word in positive_keywords:
            if pos_word in title:
                sentiment_score += 1
        for neg_word in negative_keywords:
            if neg_word in title:
                sentiment_score -= 1
        
        if relevance_score >= 3:
            analyzed_news.append({
                **news,
                'relevance_score': relevance_score,
                'sentiment_score': sentiment_score,
                'sentiment': 'positive' if sentiment_score > 0 else ('negative' if sentiment_score < 0 else 'neutral')
            })
    
    analyzed_news.sort(key=lambda x: x['relevance_score'], reverse=True)
    print(f"ğŸ” ì§€ëŠ¥í˜• ë‰´ìŠ¤ ë¶„ì„: {len(analyzed_news)}ê°œ ê´€ë ¨ ë‰´ìŠ¤ ì„ ë³„")
    return analyzed_news

def enhanced_comprehensive_analysis(events_df, matched_news_dict, matched_disclosures_dict, stock_name: str, date: str) -> str:
    """í–¥ìƒëœ ì¢…í•© ë¶„ì„"""
    
    # ì´ë²¤íŠ¸ ìš”ì•½
    event_summary = ""
    if len(events_df) > 0:
        event_summary = f"ğŸ“ˆ ì£¼ìš” ì´ë²¤íŠ¸ ({len(events_df)}ê°œ ê°ì§€):\n"
        for _, event in events_df.iterrows():
            pct = event['pct_from_start'] * 100
            event_time = event['datetime'].strftime('%H:%M')
            event_summary += f"- {event_time}: {pct:+.2f}% {event['event_type']} (â‚©{event['price']:,})\n"
    else:
        event_summary = "ğŸ“ˆ ì£¼ìš” ì´ë²¤íŠ¸:\n- 0.6% ì´ìƒì˜ ì£¼ìš” ë³€ë™ ì´ë²¤íŠ¸ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
    
    # ë‰´ìŠ¤ ìš”ì•½
    all_news = []
    for news_list in matched_news_dict.values():
        for news in news_list:
            if news['title'] not in [n['title'] for n in all_news]:
                all_news.append(news)
    
    news_summary = ""
    if all_news:
        positive_news = sum(1 for n in all_news if n.get('sentiment') == 'positive')
        negative_news = sum(1 for n in all_news if n.get('sentiment') == 'negative')
        neutral_news = len(all_news) - positive_news - negative_news
        
        news_summary = f"ğŸ“° ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë‰´ìŠ¤ ë¶„ì„ ({len(all_news)}ê°œ):\n"
        news_summary += f"- ê°ì„±ë¶„í¬: ê¸ì • {positive_news}ê°œ, ë¶€ì • {negative_news}ê°œ, ì¤‘ë¦½ {neutral_news}ê°œ\n"
        for news in all_news[:5]:
            sentiment_emoji = "ğŸ“ˆ" if news.get('sentiment') == 'positive' else ("ğŸ“‰" if news.get('sentiment') == 'negative' else "ğŸ“Š")
            news_summary += f"- {sentiment_emoji} {news['title']}\n"
    else:
        news_summary = "ğŸ“° ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë‰´ìŠ¤ ë¶„ì„:\n- ì£¼ê°€ ì´ë²¤íŠ¸ì™€ ì—°ê´€ëœ ë‰´ìŠ¤ê°€ ì—†ì–´ ë‚´ì¬ì  ì‹œì¥ ìš”ì¸ìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤.\n"
    
    # ê³µì‹œ ìš”ì•½
    all_disclosures = []
    for disc_list in matched_disclosures_dict.values():
        for disc in disc_list:
            if disc['title'] not in [d['title'] for d in all_disclosures]:
                all_disclosures.append(disc)
    
    disclosure_summary = ""
    if all_disclosures:
        disclosure_summary = f"ğŸ“‹ ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ê³µì‹œ ë¶„ì„ ({len(all_disclosures)}ê°œ):\n"
        for disc in all_disclosures[:3]:
            disclosure_summary += f"- {disc['time']}: {disc['title']}\n"
    else:
        disclosure_summary = "ğŸ“‹ ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ê³µì‹œ ë¶„ì„:\n- ì£¼ê°€ ì´ë²¤íŠ¸ì™€ ì—°ê´€ëœ ê³µì‹œê°€ ì—†ìŠµë‹ˆë‹¤.\n"
    
    # CRAG ì¢…í•© í”„ë¡¬í”„íŠ¸
    comprehensive_prompt = f"""[{date} {stock_name} CRAG ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë¶„ì„]

{event_summary}

{news_summary}

{disclosure_summary}

ğŸ¯ **CRAG ë¶„ì„ ìš”ì²­:**

ìœ„ ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë¶„ì„**: ì´ë²¤íŠ¸ ë°œìƒ ì´ì „ ì •ë³´ë“¤ê³¼ì˜ ëª…í™•í•œ ì„ í›„ê´€ê³„ ê·œëª…
2. **ì£¼ê°€ ë™í–¥ í•´ì„**: ë‹¹ì¼ ì£¼ìš” ê°€ê²© ë³€ë™ê³¼ ê±°ë˜ íŠ¹ì§•
3. **ì •ë³´ ì˜í–¥ ë¶„ì„**: ë‰´ìŠ¤ì™€ ê³µì‹œê°€ ì£¼ê°€ì— ë¯¸ì¹œ ì‹¤ì œ ì˜í–¥ë ¥ í‰ê°€
4. **ì‹œì¥ íš¨ìœ¨ì„± íŒë‹¨**: ì •ë³´ ë°˜ì˜ ì†ë„ì™€ íˆ¬ìì ë°˜ì‘ ë¶„ì„
5. **í–¥í›„ íˆ¬ì ì „ë§**: ì˜¤ëŠ˜ì˜ íŒ¨í„´ì´ í–¥í›„ì— ë¯¸ì¹  ì˜í–¥ê³¼ íˆ¬ì ì‹œì‚¬ì 

ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ íˆ¬ì ë¶„ì„ ë¦¬í¬íŠ¸ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
    
    print("ğŸ§  CRAG ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë¶„ì„ ì§„í–‰ ì¤‘...")
    return get_llm_report(comprehensive_prompt)

def search_stock_code(stock_name: str) -> tuple:
    """ì¢…ëª©ëª…ìœ¼ë¡œ ì¢…ëª© ì½”ë“œ ê²€ìƒ‰"""
    stock_db = get_stock_database()
    normalized_query = stock_name.replace(" ", "").lower()
    
    for db_name, (code, full_name) in stock_db.items():
        db_name_normalized = db_name.lower().replace(" ", "")
        if normalized_query == db_name_normalized or normalized_query in db_name_normalized:
            print(f"âœ… ì¢…ëª© ë°œê²¬: {full_name} ({code})")
            return code, full_name
    
    candidates = []
    for db_name, (code, full_name) in stock_db.items():
        db_name_lower = db_name.lower()
        if normalized_query in db_name_lower or db_name_lower in normalized_query:
            candidates.append((code, full_name))
    
    if candidates:
        print(f"\nğŸ¯ '{stock_name}'ì™€ ìœ ì‚¬í•œ ì¢…ëª©ë“¤:")
        for i, (code, name) in enumerate(candidates[:5], 1):
            print(f"{i}. {name} ({code})")
        
        try:
            choice = int(input(f"\nì„ íƒ (1-{len(candidates[:5])}): "))
            if 1 <= choice <= len(candidates[:5]):
                selected = candidates[choice - 1]
                return selected[0], selected[1]
        except ValueError:
            pass
    
    return None, None

def get_user_input():
    """ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°"""
    print("ğŸš€ ê°•í™”ëœ CRAG ì£¼ì‹ ë¶„ì„ ì‹œìŠ¤í…œ")
    print("="*50)
    
    while True:
        stock_name = input("\nğŸ“ˆ ë¶„ì„í•  ì¢…ëª©ëª…ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        if stock_name:
            stock_code, exact_name = search_stock_code(stock_name)
            if stock_code and exact_name:
                break
            else:
                print("ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        else:
            print("ì¢…ëª©ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    while True:
        print(f"\nğŸ“… ë¶„ì„ ë‚ ì§œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        print("í˜•ì‹: YYYY-MM-DD (ì˜ˆ: 2025-06-09) ë˜ëŠ” 'today'")
        
        date_input = input("ë‚ ì§œ: ").strip().lower()
        
        if date_input == "today":
            analysis_date = datetime.now().strftime("%Y-%m-%d")
            break
        else:
            try:
                datetime.strptime(date_input, "%Y-%m-%d")
                analysis_date = date_input
                break
            except ValueError:
                print("âŒ ì˜¬ë°”ë¥¸ ë‚ ì§œ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
    
    print(f"\nâœ… ì„ íƒëœ ì¢…ëª©: {exact_name} ({stock_code})")
    print(f"âœ… ë¶„ì„ ë‚ ì§œ: {analysis_date}")
    
    confirm = input("\nì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
    if confirm != 'y':
        return None, None, None
    
    return stock_code, exact_name, analysis_date

def main():
    """ê°•í™”ëœ CRAG ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    user_input = get_user_input()
    if user_input[0] is None:
        return
    
    stock_code, stock_name, date = user_input
    
    client_id = os.getenv("NAVER_CLIENT_ID") or "JEuS9xkuWGpP40lsI9Kz"
    client_secret = os.getenv("NAVER_CLIENT_SECRET") or "I6nujCm0xF"
    slack_url = os.getenv("SLACK_WEBHOOK_URL") or "https://hooks.slack.com/services/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"

    print(f"\nğŸš€ {stock_name}({stock_code}) {date} ê°•í™”ëœ CRAG ë¶„ì„ ì‹œì‘")
    print("ğŸ’¡ ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ê¸°ë°˜ ê³ ë„í™” ë¶„ì„")
    print("="*70)

    try:
        # 1. ê°•ê±´í•œ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘
        print("\nğŸ“Š 1ë‹¨ê³„: ê°•ê±´í•œ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘")
        df = robust_fetch_intraday_price(stock_code, date)
        
        # 2. í–¥ìƒëœ ì´ë²¤íŠ¸ ê°ì§€
        print("\nğŸ¯ 2ë‹¨ê³„: í–¥ìƒëœ ì´ë²¤íŠ¸ ê°ì§€")
        events = enhanced_detect_price_events_by_day(df, threshold=0.006)
        print(f"âœ… ì£¼ê°€ ë°ì´í„°: {len(df)}ê°œ ì‹œì ")
        print(f"âœ… ê°ì§€ëœ ì´ë²¤íŠ¸: {len(events)}ê°œ")

        # 3. ì§€ëŠ¥í˜• ë‰´ìŠ¤ ë¶„ì„
        print("\nğŸ“° 3ë‹¨ê³„: ì§€ëŠ¥í˜• ë‰´ìŠ¤ ë¶„ì„")
        searcher = NaverNewsSearcher(client_id, client_secret)
        raw_news_items = search_news_advanced(searcher, stock_name, date)
        formatted_news = format_news_data(raw_news_items)
        analyzed_news = intelligent_news_analysis(formatted_news, stock_name)
        print(f"âœ… ê´€ë ¨ì„± ë†’ì€ ë‰´ìŠ¤: {len(analyzed_news)}ê°œ")

        # 4. ê³µì‹œì •ë³´ ìˆ˜ì§‘
        print("\nğŸ“‹ 4ë‹¨ê³„: ê³µì‹œì •ë³´ ìˆ˜ì§‘ (3ì¼ ë²”ìœ„)")
        start_date = (datetime.strptime(date, "%Y-%m-%d") - timedelta(days=3)).strftime("%Y-%m-%d")
        disclosures = fetch_disclosures_with_fallback(stock_name, start_date, date)
        print(f"âœ… ìˆ˜ì§‘ëœ ê³µì‹œ: {len(disclosures)}ê°œ")

        # 5. CRAG ì¸ê³¼ê´€ê³„ ë¶„ì„
        print("\nğŸ”— 5ë‹¨ê³„: CRAG ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë¶„ì„")
        matched_news_dict = match_news_before_events(analyzed_news, events)
        matched_disclosures_dict = match_disclosures_before_events(disclosures, events, hours_before=72)
        
        total_matched_news = sum(len(news_list) for news_list in matched_news_dict.values())
        total_matched_disclosures = sum(len(disc_list) for disc_list in matched_disclosures_dict.values())
        print(f"âœ… ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë§¤ì¹­ - ë‰´ìŠ¤: {total_matched_news}ê°œ, ê³µì‹œ: {total_matched_disclosures}ê°œ")

        # 6. ì¢…í•© CRAG ë¶„ì„
        print("\nğŸ§  6ë‹¨ê³„: ì¢…í•© CRAG ë¶„ì„")
        analysis_result = enhanced_comprehensive_analysis(
            events, matched_news_dict, matched_disclosures_dict, stock_name, date
        )
        
        print("âœ… CRAG ë¶„ì„ ì™„ë£Œ")
        print("\n" + "="*70)
        print("ğŸ“„ CRAG ê¸°ë°˜ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸:")
        print("="*70)
        print(analysis_result)
        print("="*70)
        
        # 7. Slack ì „ì†¡ (ìµœì¢… ë¦¬í¬íŠ¸ë§Œ)
        print("\nğŸ“¨ 7ë‹¨ê³„: Slack ì „ì†¡")

        # í—¤ë“œë¼ì¸ ë‰´ìŠ¤/ê³µì‹œ ìƒ˜í”Œ 3ê°œì”© ì¶”ì¶œ
        top_news_titles = [f"- {n['title']}" for n in analyzed_news[:3]]
        top_disc_titles = [f"- {d['title']}" for d in disclosures[:3]]

        # ì‹œì¥ ì§€í‘œ ìˆ˜ì§‘
        date_fmt = datetime.strptime(date, "%Y-%m-%d").strftime("%Y.%m.%d")
        kospi_info = fetch_kospi_daily(date_fmt)
        etf_info = fetch_sector_etf_daily(etf_code="091160", date_yyyymmdd=date_fmt)

        kospi_line = (
            f"- ì½”ìŠ¤í”¼ ì§€ìˆ˜ë³€ë™ : {kospi_info.get('rate', 0):+0.2f}% "
            f"( {kospi_info.get('close', 0):,.2f} / {kospi_info.get('change', 0):+0.2f} )"
            if kospi_info and 'rate' in kospi_info else "- ì½”ìŠ¤í”¼ ì§€ìˆ˜ ì •ë³´ ì—†ìŒ"
        )
        etf_line = (
            f"- ë™ì¼ ì„¹í„°(ë°˜ë„ì²´ ETF): {etf_info.get('rate', 0):+0.2f}%"
            if etf_info and 'rate' in etf_info else "- ì„¹í„° ETF ì •ë³´ ì—†ìŒ"
        )

        # ì—…ì¢… ì •ë³´ ìˆ˜ì§‘
        industry_info = fetch_industry_info_by_stock_code(stock_code)
        industry_line = "- ì—…ì¢… ì •ë³´ ì—†ìŒ"
        if industry_info and "ì—…ì¢…ëª…" in industry_info:
            sector = industry_info.get("ì—…ì¢…ëª…", "N/A")
            change = industry_info.get("ë“±ë½ë¥ ", "N/A")
            per = industry_info.get("PER", "N/A")
            pbr = industry_info.get("PBR", "N/A")
            industry_line = f"- ë™ì¼ ì—…ì¢…({sector}): {change} / PER: {per} / PBR: {pbr}"

        final_message = f"""ğŸ¯ **{stock_name} {date} CRAG ë¶„ì„ ë¦¬í¬íŠ¸**

ğŸ“Š **ë¶„ì„ í˜„í™©:**
â€¢ ì£¼ê°€ ì‹œì : {len(df)}ê°œ
â€¢ ê°ì§€ëœ ì´ë²¤íŠ¸: {len(events)}ê°œ
â€¢ ê´€ë ¨ ë‰´ìŠ¤: {len(analyzed_news)}ê°œ
{('\n' + '\n'.join(top_news_titles)) if top_news_titles else ""}
â€¢ ìˆ˜ì§‘ ê³µì‹œ: {len(disclosures)}ê°œ
{('\n' + '\n'.join(top_disc_titles)) if top_disc_titles else ""}
â€¢ ì¸ê³¼ê´€ê³„ ë§¤ì¹­: ë‰´ìŠ¤ {total_matched_news}ê°œ, ê³µì‹œ {total_matched_disclosures}ê°œ
â€¢ ì‹œì¥ ì§€í‘œ ë¹„êµ 
{kospi_line}
{etf_line}
{industry_line}

ğŸ“ˆ **CRAG ë¶„ì„ ê²°ê³¼:**
{analysis_result}

---
*CRAG ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë¶„ì„ ì‹œìŠ¤í…œ*
"""

        send_to_slack(final_message, slack_url)
        print("âœ… CRAG ë¶„ì„ ë¦¬í¬íŠ¸ Slack ì „ì†¡ ì™„ë£Œ")

    except Exception as e:
        error_msg = f"ğŸš¨ CRAG ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}"
        print(error_msg)
        send_to_slack(error_msg, slack_url)
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()