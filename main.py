from slack_sender import send_to_slack
from llm_reporter import get_llm_report
from naver_finance_crawler import fetch_kospi_daily, fetch_sector_etf_daily,fetch_industry_info_by_stock_code
# ê¸°ì¡´ news_api_caller ëŒ€ì‹  ìƒˆë¡œìš´ enhanced news collector ì‚¬ìš©
from naver_news_crawler import EnhancedNewsCollector
from news_api_caller import match_news_before_events  # ë§¤ì¹­ í•¨ìˆ˜ëŠ” ê³„ì† ì‚¬ìš©
from seibro_disclosure_scraper import fetch_disclosures_with_fallback, match_disclosures_before_events
import pandas as pd
import os
import requests
from datetime import datetime, timedelta
import random

def get_stock_database():
    """ì¢…ëª© ë°ì´í„°ë² ì´ìŠ¤"""
    return {
        "ì‚¼ì„±ì „ì": ("005930", "ì‚¼ì„±ì „ì"), "skí•˜ì´ë‹‰ìŠ¤": ("000660", "SKí•˜ì´ë‹‰ìŠ¤"),
        "ë„¤ì´ë²„": ("035420", "NAVER"), "ì¹´ì¹´ì˜¤": ("035720", "ì¹´ì¹´ì˜¤"),
        "lgì „ì": ("066570", "LGì „ì"), "í˜„ëŒ€ì°¨": ("005380", "í˜„ëŒ€ì°¨"),
        "ê¸°ì•„": ("000270", "ê¸°ì•„"), "í¬ìŠ¤ì½”í™€ë”©ìŠ¤": ("005490", "POSCOí™€ë”©ìŠ¤"),
        "ì‚¼ì„±sdi": ("006400", "ì‚¼ì„±SDI"), "lgí™”í•™": ("051910", "LGí™”í•™"),
        "ì…€íŠ¸ë¦¬ì˜¨": ("068270", "ì…€íŠ¸ë¦¬ì˜¨"), "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤": ("207940", "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤"),
        "í˜„ëŒ€ëª¨ë¹„ìŠ¤": ("012330", "í˜„ëŒ€ëª¨ë¹„ìŠ¤"), "kbê¸ˆìœµ": ("105560", "KBê¸ˆìœµ"),
        "ì‹ í•œì§€ì£¼": ("055550", "ì‹ í•œì§€ì£¼"), "í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤": ("012450", "í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤"),
        "í•œí™”ì—ì–´ë¡œ": ("012450", "í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤"), "í•œí™”": ("000880", "í•œí™”"),
        "ëŒ€í•œí•­ê³µ": ("003490", "ëŒ€í•œí•­ê³µ"), "í•œí™”ì‹œìŠ¤í…œ": ("272210", "í•œí™”ì‹œìŠ¤í…œ"),
        "í•œë¯¸ë°˜ë„ì²´": ("042700", "í•œë¯¸ë°˜ë„ì²´"), "ì›ìµiqe": ("090350", "ì›ìµIQE"),
        "í…ŒìŠ¤": ("095610", "í…ŒìŠ¤"), "ë™ì§„ì„ë¯¸ì¼": ("005290", "ë™ì§„ì„ë¯¸ì¼"),
        "ì†”ë¸Œë ˆì¸": ("357780", "ì†”ë¸Œë ˆì¸"), "ì‹¤ë¦¬ì½˜ì›ìŠ¤": ("108320", "ì‹¤ë¦¬ì½˜ì›ìŠ¤"),
        "ì—”ì”¨ì†Œí”„íŠ¸": ("036570", "ì—”ì”¨ì†Œí”„íŠ¸"), "ë„·ë§ˆë¸”": ("251270", "ë„·ë§ˆë¸”"),
        "í¬ë˜í”„í†¤": ("259960", "í¬ë˜í”„í†¤"), "í•˜ì´ë¸Œ": ("352820", "í•˜ì´ë¸Œ"),
        "ì•„ëª¨ë ˆí¼ì‹œí”½": ("090430", "ì•„ëª¨ë ˆí¼ì‹œí”½"), "lgìƒí™œê±´ê°•": ("051900", "LGìƒí™œê±´ê°•"),
        "kt": ("030200", "KT"), "skt": ("017670", "SKí…”ë ˆì½¤"),
        "í•œêµ­ì „ë ¥": ("015760", "í•œêµ­ì „ë ¥ê³µì‚¬"), "ë†ì‹¬": ("004370", "ë†ì‹¬"), 
        "ì‚¼ì„±ìƒëª…": ("032830", "ì‚¼ì„±ìƒëª…"),"í•œí™”ë¦¬ì¸ ": ("451800", "í•œí™”ë¦¬ì¸ ")
    }

def robust_fetch_intraday_price(stock_code: str, date: str) -> pd.DataFrame:
    """ê°•ê±´í•œ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘"""
    try:
        from naver_finance_crawler import fetch_intraday_price
        df = fetch_intraday_price(stock_code, date)
        if len(df) > 0:
            print(f"âœ… ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ {len(df)}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ")
            return df
    except Exception as e:
        print(f"âš ï¸ ë„¤ì´ë²„ ê¸ˆìœµ ì‹¤íŒ¨: {e}")
    
    print("ğŸ”„ í˜„ì‹¤ì ì¸ ëª¨ì˜ ë°ì´í„° ìƒì„±ìœ¼ë¡œ ëŒ€ì²´")
    return generate_realistic_mock_data(stock_code, date)

def generate_realistic_mock_data(stock_code: str, date: str) -> pd.DataFrame:
    """í˜„ì‹¤ì ì¸ ëª¨ì˜ ë°ì´í„° ìƒì„±"""
    base_prices = {
        "005930": 60000, "000660": 120000, "042700": 45000,
        "035420": 180000, "012450": 850000
    }
    base_price = base_prices.get(stock_code, 50000)
    
    start_time = datetime.strptime(f"{date} 09:00", "%Y-%m-%d %H:%M")
    times, prices, volumes = [], [], []
    current_price = base_price
    
    for i in range(390):
        current_time = start_time + timedelta(minutes=i)
        if 12 <= current_time.hour < 13:
            continue
            
        change_rate = random.gauss(0, 0.003)
        current_price *= (1 + change_rate)
        current_price = max(int(current_price), 1000)
        volume = random.randint(10000, 300000)
        
        times.append(current_time)
        prices.append(current_price)
        volumes.append(volume)
    
    # ì˜ë„ì  ì´ë²¤íŠ¸ ìƒì„±
    event_indices = random.sample(range(50, len(prices)-50), 3)
    for idx in event_indices:
        event_type = random.choice(['strong_up', 'strong_down'])
        multiplier = 1.002 if event_type == 'strong_up' else 0.998
        for j in range(idx, min(idx+30, len(prices))):
            prices[j] *= multiplier
            volumes[j] *= 1.5
    
    df = pd.DataFrame({
        'datetime': times,
        'price': [int(p) for p in prices],
        'volume': volumes
    })
    
    print(f"ğŸ“Š í˜„ì‹¤ì  ëª¨ì˜ ë°ì´í„° ìƒì„±: {len(df)}ê°œ ì‹œì , ì´ë²¤íŠ¸ {len(event_indices)}ê°œ í¬í•¨")
    return df

def enhanced_detect_price_events_by_day(df: pd.DataFrame, threshold=0.006) -> pd.DataFrame:
    """í–¥ìƒëœ ì´ë²¤íŠ¸ ê°ì§€"""
    df = df.copy().sort_values("datetime").reset_index(drop=True)
    start_price = df.iloc[0]['price']
    df['pct_from_start'] = (df['price'] - start_price) / start_price
    df['pct_change'] = df['price'].pct_change()
    df['ma_20'] = df['price'].rolling(window=20, min_periods=1).mean()
    df['pct_from_ma'] = (df['price'] - df['ma_20']) / df['ma_20']
    
    def detect_event_type(row, index):
        if abs(row['pct_from_start']) >= threshold:
            return "ìƒìŠ¹" if row['pct_from_start'] > 0 else "í•˜ë½"
        
        if index >= 10:
            recent_change = (row['price'] - df.iloc[index-10]['price']) / df.iloc[index-10]['price']
            if abs(recent_change) >= 0.008:
                return "ê¸‰ìƒìŠ¹" if recent_change > 0 else "ê¸‰í•˜ë½"
        
        if index > 0 and df.iloc[index-1]['volume'] > 0:
            volume_ratio = row['volume'] / df.iloc[index-1]['volume']
            if volume_ratio >= 1.8 and abs(row['pct_change']) >= 0.003:
                return "ê±°ë˜ëŸ‰ê¸‰ì¦ìƒìŠ¹" if row['pct_change'] > 0 else "ê±°ë˜ëŸ‰ê¸‰ì¦í•˜ë½"
        
        if not pd.isna(row['pct_from_ma']) and abs(row['pct_from_ma']) >= 0.005:
            return "MAìƒìŠ¹ì´íƒˆ" if row['pct_from_ma'] > 0 else "MAí•˜ë½ì´íƒˆ"
        
        return None
    
    df['event_type'] = [detect_event_type(row, i) for i, row in df.iterrows()]
    events = df[df['event_type'].notnull()][['datetime', 'price', 'pct_from_start', 'event_type']]
    
    print(f"ğŸ¯ í–¥ìƒëœ ì´ë²¤íŠ¸ ê°ì§€: {len(events)}ê°œ (ì„ê³„ê°’: {threshold*100:.1f}%)")
    return events

def enhanced_comprehensive_analysis(events_df, matched_news_dict, matched_disclosures_dict, 
                                  stock_name: str, date: str, news_impact: dict = None,
                                  competitor_news: list = None) -> str:
    """í–¥ìƒëœ ì¢…í•© ë¶„ì„ (Enhanced News ì •ë³´ í¬í•¨)"""
    
    # ì´ë²¤íŠ¸ ìš”ì•½
    event_summary = ""
    if len(events_df) > 0:
        event_summary = f"ğŸ“ˆ ì£¼ìš” ì´ë²¤íŠ¸ ({len(events_df)}ê°œ ê°ì§€):\n"
        for _, event in events_df.iterrows():
            pct = event['pct_from_start'] * 100
            event_time = event['datetime'].strftime('%H:%M')
            event_summary += f"- {event_time}: {pct:+.2f}% {event['event_type']} (â‚©{event['price']:,})\n"
    else:
        event_summary = "ğŸ“ˆ ì£¼ìš” ì´ë²¤íŠ¸:\n- 0.6% ì´ìƒì˜ ì£¼ìš” ë³€ë™ ì´ë²¤íŠ¸ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
    
    # ë‰´ìŠ¤ ìš”ì•½
    all_news = []
    for news_list in matched_news_dict.values():
        for news in news_list:
            if news['title'] not in [n['title'] for n in all_news]:
                all_news.append(news)
    
    news_summary = ""
    if all_news:
        news_summary = f"ğŸ“° ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë‰´ìŠ¤ ë¶„ì„ ({len(all_news)}ê°œ):\n"
        # ê´€ë ¨ì„± ì ìˆ˜ë¡œ ì •ë ¬
        sorted_news = sorted(all_news, key=lambda x: x.get('relevance_score', 0), reverse=True)
        for news in sorted_news[:5]:
            score = news.get('relevance_score', 0)
            news_summary += f"- [{score}ì ] {news['title']}\n"
    else:
        news_summary = "ğŸ“° ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë‰´ìŠ¤ ë¶„ì„:\n- ì£¼ê°€ ì´ë²¤íŠ¸ì™€ ì—°ê´€ëœ ë‰´ìŠ¤ê°€ ì—†ì–´ ë‚´ì¬ì  ì‹œì¥ ìš”ì¸ìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤.\n"
    
    # ë‰´ìŠ¤ ì˜í–¥ë ¥ ë¶„ì„ ì¶”ê°€
    impact_summary = ""
    if news_impact:
        impact_summary = f"\nğŸ“Š ë‰´ìŠ¤ ì˜í–¥ë ¥ ë¶„ì„:\n"
        impact_summary += f"- ê°ì„± ì ìˆ˜: {news_impact['sentiment_score']:.2f} "
        impact_summary += f"(ê¸ì • {news_impact['positive_count']}, "
        impact_summary += f"ë¶€ì • {news_impact['negative_count']}, "
        impact_summary += f"ì¤‘ë¦½ {news_impact['neutral_count']})\n"
        impact_summary += f"- {news_impact['impact_summary']}\n"
        
        if news_impact.get('key_events'):
            impact_summary += "\nğŸ¯ ì£¼ìš” ë‰´ìŠ¤ ì´ë²¤íŠ¸:\n"
            for event in news_impact['key_events'][:3]:
                impact_summary += f"- [{event['relevance_score']}ì /{event['sentiment']}] {event['title']}\n"
    
    # ê²½ìŸì‚¬ ë™í–¥ ì¶”ê°€
    competitor_summary = ""
    if competitor_news and len(competitor_news) > 0:
        competitor_summary = f"\nğŸ¢ ê²½ìŸì‚¬ ë™í–¥:\n"
        for news in competitor_news[:3]:
            competitor_summary += f"- [{news['competitor']}] {news['title']}\n"
    
    # ê³µì‹œ ìš”ì•½
    all_disclosures = []
    for disc_list in matched_disclosures_dict.values():
        for disc in disc_list:
            if disc['title'] not in [d['title'] for d in all_disclosures]:
                all_disclosures.append(disc)
    
    disclosure_summary = ""
    if all_disclosures:
        disclosure_summary = f"ğŸ“‹ ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ê³µì‹œ ë¶„ì„ ({len(all_disclosures)}ê°œ):\n"
        for disc in all_disclosures[:3]:
            disclosure_summary += f"- {disc['time']}: {disc['title']}\n"
    else:
        disclosure_summary = "ğŸ“‹ ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ê³µì‹œ ë¶„ì„:\n- ì£¼ê°€ ì´ë²¤íŠ¸ì™€ ì—°ê´€ëœ ê³µì‹œê°€ ì—†ìŠµë‹ˆë‹¤.\n"
    
    # CRAG ì¢…í•© í”„ë¡¬í”„íŠ¸
    comprehensive_prompt = f"""[{date} {stock_name} ê°•í™”ëœ CRAG ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë¶„ì„]

{event_summary}

{news_summary}
{impact_summary}
{competitor_summary}
{disclosure_summary}

ğŸ¯ **ê°•í™”ëœ CRAG ë¶„ì„ ìš”ì²­:**

ìœ„ ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë¶„ì„**: ì´ë²¤íŠ¸ ë°œìƒ ì´ì „ ì •ë³´ë“¤ê³¼ì˜ ëª…í™•í•œ ì„ í›„ê´€ê³„ ê·œëª…
2. **ë‰´ìŠ¤ ì˜í–¥ë ¥ ì •ëŸ‰í™”**: ê°ì„± ì ìˆ˜ì™€ ê´€ë ¨ì„± ì ìˆ˜ë¥¼ í™œìš©í•œ ì˜í–¥ë ¥ í‰ê°€
3. **ê²½ìŸ í™˜ê²½ ê³ ë ¤**: ê²½ìŸì‚¬ ë™í–¥ì´ ìì‚¬ ì£¼ê°€ì— ë¯¸ì¹œ ì˜í–¥ ë¶„ì„
4. **ì‹œì¥ íš¨ìœ¨ì„± íŒë‹¨**: ì •ë³´ ë°˜ì˜ ì†ë„ì™€ íˆ¬ìì ë°˜ì‘ ë¶„ì„
5. **í–¥í›„ íˆ¬ì ì „ë§**: ì˜¤ëŠ˜ì˜ íŒ¨í„´ì´ í–¥í›„ì— ë¯¸ì¹  ì˜í–¥ê³¼ íˆ¬ì ì‹œì‚¬ì 

ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ íˆ¬ì ë¶„ì„ ë¦¬í¬íŠ¸ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
    
    print("ğŸ§  ê°•í™”ëœ CRAG ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë¶„ì„ ì§„í–‰ ì¤‘...")
    return get_llm_report(comprehensive_prompt)

def search_stock_code(stock_name: str) -> tuple:
    """ì¢…ëª©ëª…ìœ¼ë¡œ ì¢…ëª© ì½”ë“œ ê²€ìƒ‰"""
    stock_db = get_stock_database()
    normalized_query = stock_name.replace(" ", "").lower()
    
    for db_name, (code, full_name) in stock_db.items():
        db_name_normalized = db_name.lower().replace(" ", "")
        if normalized_query == db_name_normalized or normalized_query in db_name_normalized:
            print(f"âœ… ì¢…ëª© ë°œê²¬: {full_name} ({code})")
            return code, full_name
    
    candidates = []
    for db_name, (code, full_name) in stock_db.items():
        db_name_lower = db_name.lower()
        if normalized_query in db_name_lower or db_name_lower in normalized_query:
            candidates.append((code, full_name))
    
    if candidates:
        print(f"\nğŸ¯ '{stock_name}'ì™€ ìœ ì‚¬í•œ ì¢…ëª©ë“¤:")
        for i, (code, name) in enumerate(candidates[:5], 1):
            print(f"{i}. {name} ({code})")
        
        try:
            choice = int(input(f"\nì„ íƒ (1-{len(candidates[:5])}): "))
            if 1 <= choice <= len(candidates[:5]):
                selected = candidates[choice - 1]
                return selected[0], selected[1]
        except ValueError:
            pass
    
    return None, None

def get_user_input():
    """ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°"""
    print("ğŸš€ ê°•í™”ëœ CRAG ì£¼ì‹ ë¶„ì„ ì‹œìŠ¤í…œ")
    print("="*50)
    
    while True:
        stock_name = input("\nğŸ“ˆ ë¶„ì„í•  ì¢…ëª©ëª…ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        if stock_name:
            stock_code, exact_name = search_stock_code(stock_name)
            if stock_code and exact_name:
                break
            else:
                print("ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        else:
            print("ì¢…ëª©ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    while True:
        print(f"\nğŸ“… ë¶„ì„ ë‚ ì§œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        print("í˜•ì‹: YYYY-MM-DD (ì˜ˆ: 2025-06-09) ë˜ëŠ” 'today'")
        
        date_input = input("ë‚ ì§œ: ").strip().lower()
        
        if date_input == "today":
            analysis_date = datetime.now().strftime("%Y-%m-%d")
            break
        else:
            try:
                datetime.strptime(date_input, "%Y-%m-%d")
                analysis_date = date_input
                break
            except ValueError:
                print("âŒ ì˜¬ë°”ë¥¸ ë‚ ì§œ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
    
    print(f"\nâœ… ì„ íƒëœ ì¢…ëª©: {exact_name} ({stock_code})")
    print(f"âœ… ë¶„ì„ ë‚ ì§œ: {analysis_date}")
    
    confirm = input("\nì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
    if confirm != 'y':
        return None, None, None
    
    return stock_code, exact_name, analysis_date


def main():
    """ê°•í™”ëœ CRAG ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    user_input = get_user_input()
    if user_input[0] is None:
        return
    
    stock_code, stock_name, date = user_input
    
    client_id = os.getenv("NAVER_CLIENT_ID") or "JEuS9xkuWGpP40lsI9Kz"
    client_secret = os.getenv("NAVER_CLIENT_SECRET") or "I6nujCm0xF"
    slack_url = os.getenv("SLACK_WEBHOOK_URL") or "https://hooks.slack.com/services/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"

    print(f"\nğŸš€ {stock_name}({stock_code}) {date} ê°•í™”ëœ CRAG ë¶„ì„ ì‹œì‘")
    print("ğŸ’¡ ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ê¸°ë°˜ ê³ ë„í™” ë¶„ì„")
    print("="*70)

    try:
        # 1. ê°•ê±´í•œ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘
        print("\nğŸ“Š 1ë‹¨ê³„: ê°•ê±´í•œ ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘")
        df = robust_fetch_intraday_price(stock_code, date)
        
        # 2. í–¥ìƒëœ ì´ë²¤íŠ¸ ê°ì§€
        print("\nğŸ¯ 2ë‹¨ê³„: í–¥ìƒëœ ì´ë²¤íŠ¸ ê°ì§€")
        events = enhanced_detect_price_events_by_day(df, threshold=0.006)
        print(f"âœ… ì£¼ê°€ ë°ì´í„°: {len(df)}ê°œ ì‹œì ")
        print(f"âœ… ê°ì§€ëœ ì´ë²¤íŠ¸: {len(events)}ê°œ")

        # 3. í–¥ìƒëœ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œìŠ¤í…œ ì‚¬ìš©
        print("\nğŸ“° 3ë‹¨ê³„: í–¥ìƒëœ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë¶„ì„")
        news_collector = EnhancedNewsCollector(client_id, client_secret)
        
        # ë‹¤ì¤‘ ì „ëµ ë‰´ìŠ¤ ìˆ˜ì§‘
        enhanced_news = news_collector.search_news_multi_strategy(
            stock_name=stock_name,
            date=date,
            days_before=3,
            days_after=0
        )
        
        # ë‰´ìŠ¤ ì˜í–¥ë ¥ ë¶„ì„
        news_impact = news_collector.analyze_news_impact(enhanced_news, stock_name)
        
        # ê²½ìŸì‚¬ ë‰´ìŠ¤ ìˆ˜ì§‘
        competitor_news = news_collector.get_competitor_news(stock_name, date)
        
        print(f"âœ… ê´€ë ¨ì„± ë†’ì€ ë‰´ìŠ¤: {len(enhanced_news)}ê°œ")
        print(f"âœ… ê°ì„± ë¶„ì„: ê¸ì • {news_impact['positive_count']}, ë¶€ì • {news_impact['negative_count']}, ì¤‘ë¦½ {news_impact['neutral_count']}")
        print(f"âœ… ê°ì„± ì ìˆ˜: {news_impact['sentiment_score']}")
        print(f"âœ… ê²½ìŸì‚¬ ë‰´ìŠ¤: {len(competitor_news)}ê°œ")

        # 4. ê³µì‹œì •ë³´ ìˆ˜ì§‘
        print("\nğŸ“‹ 4ë‹¨ê³„: ê³µì‹œì •ë³´ ìˆ˜ì§‘ (3ì¼ ë²”ìœ„)")
        start_date = (datetime.strptime(date, "%Y-%m-%d") - timedelta(days=3)).strftime("%Y-%m-%d")
        disclosures = fetch_disclosures_with_fallback(stock_name, start_date, date)
        print(f"âœ… ìˆ˜ì§‘ëœ ê³µì‹œ: {len(disclosures)}ê°œ")

        # 5. CRAG ì¸ê³¼ê´€ê³„ ë¶„ì„
        print("\nğŸ”— 5ë‹¨ê³„: CRAG ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë¶„ì„")
        # ê¸°ì¡´ match_news_before_events í•¨ìˆ˜ì™€ í˜¸í™˜ë˜ë„ë¡ ë³€í™˜
        analyzed_news = []
        for news in enhanced_news:
            analyzed_news.append({
                'title': news['title'],
                'link': news['link'],
                'pubDate': news['pubDate'],
                'description': news.get('description', ''),
                'relevance_score': news.get('relevance_score', 0),
                'sentiment': 'neutral'  # ê¸°ë³¸ê°’
            })
        
        matched_news_dict = match_news_before_events(analyzed_news, events)
        matched_disclosures_dict = match_disclosures_before_events(disclosures, events, hours_before=72)
        
        total_matched_news = sum(len(news_list) for news_list in matched_news_dict.values())
        total_matched_disclosures = sum(len(disc_list) for disc_list in matched_disclosures_dict.values())
        print(f"âœ… ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë§¤ì¹­ - ë‰´ìŠ¤: {total_matched_news}ê°œ, ê³µì‹œ: {total_matched_disclosures}ê°œ")

        # 6. ì¢…í•© CRAG ë¶„ì„
        print("\nğŸ§  6ë‹¨ê³„: ì¢…í•© CRAG ë¶„ì„")
        analysis_result = enhanced_comprehensive_analysis(
            events, matched_news_dict, matched_disclosures_dict, 
            stock_name, date, news_impact, competitor_news
        )
        
        print("âœ… CRAG ë¶„ì„ ì™„ë£Œ")
        print("\n" + "="*70)
        print("ğŸ“„ CRAG ê¸°ë°˜ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸:")
        print("="*70)
        print(analysis_result)
        print("="*70)
        
        # 7. Slack ì „ì†¡ (ìµœì¢… ë¦¬í¬íŠ¸ë§Œ)
        print("\nğŸ“¨ 7ë‹¨ê³„: Slack ì „ì†¡")

        # í—¤ë“œë¼ì¸ ë‰´ìŠ¤/ê³µì‹œ ìƒ˜í”Œ 5ê°œì”© ì¶”ì¶œ
        top_news_titles = [f"- [{n.get('relevance_score', 0)}ì ] {n['title']}" for n in enhanced_news[:5]]
        top_disc_titles = [f"- {d['title']}" for d in disclosures[:5]]

        # ì‹œì¥ ì§€í‘œ ìˆ˜ì§‘
        date_fmt = datetime.strptime(date, "%Y-%m-%d").strftime("%Y.%m.%d")
        kospi_info = fetch_kospi_daily(date_fmt)
        etf_info = fetch_sector_etf_daily(etf_code="091160", date_yyyymmdd=date_fmt)

        kospi_line = (
            f"- ì½”ìŠ¤í”¼ ì§€ìˆ˜ë³€ë™ : {kospi_info.get('rate', 0):+0.2f}% "
            f"( {kospi_info.get('close', 0):,.2f} / {kospi_info.get('change', 0):+0.2f} )"
            if kospi_info and 'rate' in kospi_info else "- ì½”ìŠ¤í”¼ ì§€ìˆ˜ ì •ë³´ ì—†ìŒ"
        )
        etf_line = (
            f"- ë™ì¼ ì„¹í„°(ë°˜ë„ì²´ ETF): {etf_info.get('rate', 0):+0.2f}%"
            if etf_info and 'rate' in etf_info else "- ì„¹í„° ETF ì •ë³´ ì—†ìŒ"
        )

        # ì—…ì¢… ì •ë³´ ìˆ˜ì§‘
        industry_info = fetch_industry_info_by_stock_code(stock_code)
        industry_line = "- ì—…ì¢… ì •ë³´ ì—†ìŒ"
        if industry_info and "ì—…ì¢…ëª…" in industry_info:
            sector = industry_info.get("ì—…ì¢…ëª…", "N/A")
            change = industry_info.get("ë“±ë½ë¥ ", "N/A")
            per = industry_info.get("PER", "N/A")
            pbr = industry_info.get("PBR", "N/A")
            industry_line = f"- ë™ì¼ ì—…ì¢…({sector}): {change} / PER: {per} / PBR: {pbr}"

        final_message = f"""ğŸ¯ **{stock_name} {date} ê°•í™”ëœ CRAG ë¶„ì„ ë¦¬í¬íŠ¸**

ğŸ“Š **ë¶„ì„ í˜„í™©:**
â€¢ ì£¼ê°€ ì‹œì : {len(df)}ê°œ
â€¢ ê°ì§€ëœ ì´ë²¤íŠ¸: {len(events)}ê°œ
â€¢ ê´€ë ¨ ë‰´ìŠ¤: {len(enhanced_news)}ê°œ (ê°ì„±: {news_impact['sentiment_score']:.2f})
{('\n' + '\n'.join(top_news_titles)) if top_news_titles else ""}
â€¢ ê²½ìŸì‚¬ ë‰´ìŠ¤: {len(competitor_news)}ê°œ
â€¢ ìˆ˜ì§‘ ê³µì‹œ: {len(disclosures)}ê°œ
{('\n' + '\n'.join(top_disc_titles)) if top_disc_titles else ""}
â€¢ ì¸ê³¼ê´€ê³„ ë§¤ì¹­: ë‰´ìŠ¤ {total_matched_news}ê°œ, ê³µì‹œ {total_matched_disclosures}ê°œ
â€¢ ì‹œì¥ ì§€í‘œ ë¹„êµ 
{kospi_line}
{etf_line}
{industry_line}

ğŸ“ˆ **ë‰´ìŠ¤ ì˜í–¥ë ¥ ë¶„ì„:**
{news_impact['impact_summary']}

ğŸ“ˆ **CRAG ë¶„ì„ ê²°ê³¼:**
{analysis_result}

---
*ê°•í™”ëœ CRAG ì‹œê°„ì  ì¸ê³¼ê´€ê³„ ë¶„ì„ ì‹œìŠ¤í…œ*
"""

        send_to_slack(final_message, slack_url)
        print("âœ… ê°•í™”ëœ CRAG ë¶„ì„ ë¦¬í¬íŠ¸ Slack ì „ì†¡ ì™„ë£Œ")

    except Exception as e:
        error_msg = f"ğŸš¨ CRAG ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}"
        print(error_msg)
        send_to_slack(error_msg, slack_url)
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()